{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:26.095878Z",
     "iopub.status.busy": "2025-01-24T06:06:26.095581Z",
     "iopub.status.idle": "2025-01-24T06:06:46.036217Z",
     "shell.execute_reply": "2025-01-24T06:06:46.035498Z",
     "shell.execute_reply.started": "2025-01-24T06:06:26.095857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.1\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes \n",
    "!pip install PyMuPDF\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM)\n",
    "\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "from transformers.cache_utils import DynamicCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:46.037615Z",
     "iopub.status.busy": "2025-01-24T06:06:46.037245Z",
     "iopub.status.idle": "2025-01-24T06:06:46.040891Z",
     "shell.execute_reply": "2025-01-24T06:06:46.040131Z",
     "shell.execute_reply.started": "2025-01-24T06:06:46.037583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "HF_TOKEN = r\"YOUR_HF_TOKEN_HERE\"\n",
    "MODEL_NAME = r\"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:46.043204Z",
     "iopub.status.busy": "2025-01-24T06:06:46.042877Z",
     "iopub.status.idle": "2025-01-24T06:06:47.892050Z",
     "shell.execute_reply": "2025-01-24T06:06:47.891221Z",
     "shell.execute_reply.started": "2025-01-24T06:06:46.043177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "PDF_PATH = r\"Information Retrieval Implementing and Evaluating Search Engines.pdf\"\n",
    "document = fitz.open(PDF_PATH)\n",
    "\n",
    "text = str()\n",
    "for page_num in range(len(document)):\n",
    "    page = document.load_page(page_num)\n",
    "    text += page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.893308Z",
     "iopub.status.busy": "2025-01-24T06:06:47.893093Z",
     "iopub.status.idle": "2025-01-24T06:06:47.911583Z",
     "shell.execute_reply": "2025-01-24T06:06:47.898756Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.893290Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n a single section from a long\n",
      "technical manual.\n",
      "1.3\n",
      "Working with Electronic Text\n",
      "13\n",
      "Other document formats are proprietary, meaning they are associated with the products\n",
      "of a single software manufacturer. These proprietary formats include Microsoft’s “doc” format.\n",
      "Until recently, due to the market dominance of Microsoft Oﬃce, this format was widely used for\n",
      "document exchange and collaboration. Although the technical speciﬁcations for such proprietary\n",
      "formats are often available, they can be complex and may be modiﬁed substantially from version\n",
      "to version, entirely at the manufacturer’s discretion. Microsoft and other manufacturers have\n",
      "now shifted toward XML-based formats (such as the OpenDocument format or Microsoft’s\n",
      "OOXML), which may ameliorate the complications of indexing.\n",
      "In practice, HTML may share many of the problems of binary formats. Many HTML pages\n",
      "include scripts in the JavaScript or Flash programming languages. These scripts may rewrite\n",
      "the Web page in its entirety and display arbitrary content on the screen. On pages in which the\n",
      "content is generated by scripts, it may be a practical impossibility for Web crawlers and search\n",
      "engines to extract and index meaningful content.\n",
      "1.3.2\n",
      "A Simple Tokenization of English Text\n",
      "Regardless of a document’s format, the construction of an inverted index that can be used\n",
      "to process search queries requires each document to be converted into a sequence of tokens.\n",
      "For English-language documents, a token usually corresponds to a sequence of alphanumeric\n",
      "characters (A to Z and 0 to 9), but it may also encode structural information, such as XML\n",
      "tags, or other characteristics of the text. Tokenization is a critical step in the indexing process\n",
      "because it eﬀectively limits the class of queries that may be processed by the system.\n",
      "As a preliminary step before tokenization, documents in binary formats must be converted to\n",
      "raw text — a stream of characters. The process of converting a document to raw text generally\n",
      "discards font information and other lower-level physical formatting but may retain higher-level\n",
      "logical formatting, perhaps by re-inserting appropriate tags into the raw text. This higher-level\n",
      "formatting might include titles, paragraph boundaries, and similar elements. This preliminary\n",
      "step is not required for documents in XML or HTML because these already contain the tokens\n",
      "in the order required for indexing, thus simplifying the processing cost substantially. Essentially,\n",
      "these formats are in situ raw text.\n",
      "For English-language documents, characters in the raw text may be encoded as seven-bit\n",
      "ASCII values. However, ASCII is not suﬃcient for documents in other languages. For these\n",
      "languages, other coding schemes must be used, and it may not be possible to encode each\n",
      "character as a single byte. The UTF-8 representation of Unicode provides one popular method\n",
      "for encoding these characters (see Section 3.2). UTF-8 provides a one-to-four byte encoding for\n",
      "the characters in most living languages, as well as for those in many extinct languages, such\n",
      "as Phoenician and Sumerian cuneiform. UTF-8 is backwards compatible with ASCII, so that\n",
      "ASCII text is automatically UTF-8 text.\n",
      "To tokenize the XML in Figure 1.3, we treat each XML tag and each sequence of consecutive\n",
      "alphanumeric characters as a token. We convert uppercase letters outside tags to lowercase in\n",
      "order to simplify the matching process, meaning that “FIRST”, “ﬁrst” and “First” are treated\n",
      "Chapter 1\n",
      "Introduction\n",
      "14\n",
      "· · ·\n",
      "745396\n",
      "<STAGEDIR>\n",
      "745397\n",
      "thunder\n",
      "745398\n",
      "and\n",
      "745399\n",
      "lightning\n",
      "745400\n",
      "enter\n",
      "745401\n",
      "three\n",
      "745402\n",
      "witches\n",
      "745403\n",
      "</STAGEDIR>\n",
      "745404\n",
      "<SPEECH>\n",
      "745405\n",
      "<SPEAKER>\n",
      "745406\n",
      "first\n",
      "745407\n",
      "witch\n",
      "745408\n",
      "</SPEAKER>\n",
      "745409\n",
      "<LINE>\n",
      "745410\n",
      "when\n",
      "745411\n",
      "shall\n",
      "745412\n",
      "we\n",
      "745413\n",
      "three\n",
      "745414\n",
      "meet\n",
      "745415\n",
      "again\n",
      "745416\n",
      "</LINE>\n",
      "745417\n",
      "<LINE>\n",
      "745418\n",
      "in\n",
      "745419\n",
      "thunder\n",
      "745420\n",
      "lightning\n",
      "745421\n",
      "or\n",
      "745422\n",
      "in\n",
      "745423\n",
      "rain\n",
      "745424\n",
      "</LINE>\n",
      "745425\n",
      "</SPEECH>\n",
      "745426\n",
      "<SPEECH>\n",
      "745427\n",
      "<SPEAKER>\n",
      "745428\n",
      "second\n",
      "745429\n",
      "witch\n",
      "745430\n",
      "</SPEAKER>\n",
      "· · ·\n",
      "Figure 1.4\n",
      "A tokenization of Shakespeare’s Macbeth.\n",
      "as equivalent. The result of our tokenization is shown in Figure 1.4. Each token is accompanied\n",
      "by an integer that indicates its position in a collection of Shakespeare’s 37 plays, starting with\n",
      "position 1 at the beginning of Antony and Cleopatra and ﬁnishing with position 1,271,504 at the\n",
      "end of The Winter’s Tale. This simple approach to tokenization is suﬃcient for our purposes\n",
      "through the remainder of Chapters 1 and 2, and it is assumed where necessary. We will reexamine\n",
      "tokenization for English and other languages in Chapter 3.\n",
      "The set of distinct tokens, or symbols, in a text collection is called the vocabulary, denoted\n",
      "as V. Our collection of Shakespeare’s plays has |V| = 22,987 symbols in its vocabulary.\n",
      "V = {a, aaron, abaissiez, ..., zounds, zwaggered, ..., <PLAY>, ..., <SPEAKER>, ..., </PLAY>, ...}\n",
      "1.3\n",
      "Working with Electronic Text\n",
      "15\n",
      "Table 1.1\n",
      "The twenty most frequent terms in Bosak’s XML version of Shakespeare.\n",
      "Rank\n",
      "Frequency\n",
      "Token\n",
      "Rank\n",
      "Frequency\n",
      "Token\n",
      "1\n",
      "107,833\n",
      "<LINE>\n",
      "11\n",
      "17,523\n",
      "of\n",
      "2\n",
      "107,833\n",
      "</LINE>\n",
      "12\n",
      "14,914\n",
      "a\n",
      "3\n",
      "31,081\n",
      "<SPEAKER>\n",
      "13\n",
      "14,088\n",
      "you\n",
      "4\n",
      "31,081\n",
      "</SPEAKER>\n",
      "14\n",
      "12,287\n",
      "my\n",
      "5\n",
      "31,028\n",
      "<SPEECH>\n",
      "15\n",
      "11,192\n",
      "that\n",
      "6\n",
      "31,028\n",
      "</SPEECH>\n",
      "16\n",
      "11,106\n",
      "in\n",
      "7\n",
      "28,317\n",
      "the\n",
      "17\n",
      "9,344\n",
      "is\n",
      "8\n",
      "26,022\n",
      "and\n",
      "18\n",
      "8,506\n",
      "not\n",
      "9\n",
      "22,639\n",
      "i\n",
      "19\n",
      "7,799\n",
      "it\n",
      "10\n",
      "19,898\n",
      "to\n",
      "20\n",
      "7,753\n",
      "me\n",
      "For Shakespeare, the vocabulary includes 22,943 words and 44 tags, in which we consider any\n",
      "string of alphanumeric characters to be a word. In this book, we usually refer to symbols in the\n",
      "vocabulary as “terms” because they form the basis for matching against the terms in a query.\n",
      "In addition, we often refer to a token as an “occurrence” of a term. Although this usage helps\n",
      "reinforce the link between the tokens in a document and the terms in a query, it may obscure\n",
      "the crucial diﬀerence between a symbol and a token. A symbol is an abstraction; a token is an\n",
      "instance of that abstraction. In philosophy, this diﬀerence is called the “type-token distinction.”\n",
      "In object-oriented programming, it is the diﬀerence between a class and an object.\n",
      "1.3.3\n",
      "Term Distributions\n",
      "Table 1.1 lists the twenty most frequent terms in the XML collection of Shakespeare’s plays. Of\n",
      "these terms, the top six are tags for lines, speakers, and speeches. As is normally true for English\n",
      "text, “the” is the most frequent word, followed by various pronouns, prepositions, and other\n",
      "function words. More than one-third (8,336) of the terms, such as “abaissiez” and “zwaggered”,\n",
      "appear only once.\n",
      "The frequency of the tags is determined by the structural constraints of the collection. Each\n",
      "start tag <name> has a corresponding end tag </name>. Each play has exactly one title. Each\n",
      "speech has at least one speaker, but a few speeches have more than one speaker, when a group\n",
      "of characters speak in unison. On average, a new line starts every eight or nine words.\n",
      "While the type and relative frequency of tags will be diﬀerent in other collections, the relative\n",
      "frequency of words in English text usually follows a consistent pattern. Figure 1.5 plots the\n",
      "frequency of the terms in Shakespeare in rank order, with tags omitted. Logarithmic scales are\n",
      "used for both the x and the y axes. The points fall roughly along a line with slope −1, although\n",
      "both the most frequent and the least frequent terms fall below the line. On this plot, the point\n",
      "Chapter 1\n",
      "Introduction\n",
      "16\n",
      " 1\n",
      " 10\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      " 1\n",
      " 10\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "Frequency (log. scale)\n",
      "Rank (log. scale)\n",
      "Figure 1.5\n",
      "Frequency of words in the Shakespeare collection, by rank order. The dashed line\n",
      "corresponds to Zipf’s law with α = 1.\n",
      "corresponding to “the” appears in the upper left. The point corresponding to “zwaggered”\n",
      "appears in the lower right, together with the other words that appear exactly once.\n",
      "The relationship between frequency and rank represented by this line is known as Zipf’s law,\n",
      "after the linguist George Zipf, who developed it in the 1930s and used it to model the relative\n",
      "frequencies of data across a number of areas in the social sciences (Zipf, 1949). Mathematically,\n",
      "the relationship may be expressed as\n",
      "log(frequency) = C −α · log(rank) ,\n",
      "(1.1)\n",
      "or equivalently as\n",
      "Fi ∼1\n",
      "iα ,\n",
      "(1.2)\n",
      "where Fi is the frequency of the ith most frequent term. For English text, the value of α may\n",
      "vary, but it is usually close to 1. Zipf’s law is known to apply to the relative word frequencies\n",
      "in other natural languages, as well as to other types of data. In Chapter 4, it motivates the use\n",
      "of a certain data structure for indexing natural language text. In Chapter 15, we apply Zipf’s\n",
      "law to model the relative frequency of search engine queries.\n",
      "1.3\n",
      "Working with Electronic Text\n",
      "17\n",
      "1.3.4\n",
      "Language Modeling\n",
      "There are 912,052 tokens in Bosak’s XML version of Shakespeare’s plays, excluding tags (but\n",
      "including some front matter that does not appear in the original versions). If we pick a token\n",
      "uniformly at random from these plays, the probability of picking “the” is 28, 317/912, 052 ≈\n",
      "3.1%, whereas the probability of picking “zwaggered” is only 1/912, 052 ≈0.00011%. Now,\n",
      "imagine that a previously unknown Shakespearean play is discovered. Can we predict anything\n",
      "about the content of this play from what we know of the existing plays? In making these\n",
      "predictions, we redeﬁne the vocabulary V to exclude tags. An unknown Shakespearean play is\n",
      "unlikely to be encoded in XML (at least when it is ﬁrst discovered).\n",
      "Predictions concerning the content of unseen text may be made by way of a special kind of\n",
      "probability distribution known as a language model. The simplest language model is a ﬁxed\n",
      "probability distribution M(σ) over the symbols in the vocabulary:\n",
      "\u0002\n",
      "σ∈V\n",
      "M(σ) = 1.\n",
      "(1.3)\n",
      "A language model is often based on an existing text. For example, we might deﬁne\n",
      "M(σ) =\n",
      "frequency(σ)\n",
      "\u0003\n",
      "σ′∈V frequency(σ′)\n",
      "(1.4)\n",
      "where frequency(σ) represents the number of occurrences of the term σ in Shakespeare’s plays.\n",
      "Thus, we have M(“the”) ≈3.1% and M(“zwaggered”) ≈0.00011%.\n",
      "If we pick a token uniformly at random from Shakespeare’s known plays, the probably of\n",
      "picking the term σ is M(σ). Based on this knowledge of Shakespeare, if we pick a token\n",
      "uniformly at random from the previously unseen play, we might assume that the probably of\n",
      "picking σ is also M(σ). If we start reading the unseen play, we can use the language model\n",
      "to make a prediction about the next term in the text, with M(σ) giving the probability that\n",
      "the next term is σ. For this simple language model, we consider each term in isolation. The\n",
      "language model makes the same independent prediction concerning the ﬁrst term, and the next,\n",
      "and the next, and so on. Based on this language model, the probability that the next six terms\n",
      "are “to be or not to be” is:\n",
      "2.18% × 0.76% × 0.27% × 0.93% × 2.18% × 0.76% = 0.000000000069%.\n",
      "Equation 1.4 is called the maximum likelihood estimate (MLE) for this simple type of language\n",
      "model. In general, maximum likelihood is the standard method for estimating unknown param-\n",
      "eters of a probability distribution, given a set of data. Here, we have a parameter corresponding\n",
      "to each term — the probability that the term appears next in the unseen text. Roughly speak-\n",
      "ing, the maximum likelihood estimation method chooses values for the parameters that make\n",
      "the data set most likely. In this case, we are treating the plays of Shakespeare as providing the\n",
      "necessary data set. Equation 1.4 is the assignment of probabilities that is most likely to produce\n",
      "Chapter 1\n",
      "Introduction\n",
      "18\n",
      "Shakespeare. If we assume that the unseen text is similar to the existing text, the maximum\n",
      "likelihood model provides a good starting point for predicting its content.\n",
      "Language models can be used to quantify how close a new text fragment is to an existing\n",
      "corpus. Suppose we have a language model representing the works of Shakespeare and another\n",
      "representing the works of the English playwrightJohn Webster. A new, previously unknown,\n",
      "play is found; experts debate about who might be its author. Assuming that our two language\n",
      "models capture salient characteristics of the two writers, such as their preferred vocabulary, we\n",
      "may apply the language models to compute the probability of the new text according to each.\n",
      "The language model that assigns the higher probability to the new text may indicate its author.\n",
      "However, a language model need not use maximum likelihood estimates. Any probability\n",
      "distribution over a vocabulary of terms may be treated as a language model. For example,\n",
      "consider the probability distribution\n",
      "M(“to”) = 0.40\n",
      "M(“be”) = 0.30\n",
      "M(“or”) = 0.20\n",
      "M(“not”) = 0.10.\n",
      "Based on this distribution, the probability that the next six words are “to be or not to be” is\n",
      "0.40 × 0.30 × 0.20 × 0.10 × 0.40 × 0.30 = 0.029%.\n",
      "Of course, based on this model, the probability that the next six words are “the lady doth\n",
      "protest too much” is zero.\n",
      "In practice, unseen text might include unseen terms. To accommodate these unseen terms,\n",
      "the vocabulary might be extended by adding an unknown symbol to represent these “out-of-\n",
      "vocabulary” terms.\n",
      "V′ = V ∪{unknown}\n",
      "(1.5)\n",
      "The corresponding extended language model M′(σ) would then assign a positive probability to\n",
      "this unknown term\n",
      "M′(unknown) = β,\n",
      "(1.6)\n",
      "where 0 ≤β ≤1. The value β represents the probability that the next term does not appear in\n",
      "the existing collection from which the model M was estimated. For other terms, we might then\n",
      "deﬁne\n",
      "M′(σ) = M(σ) · (1 −β) ,\n",
      "(1.7)\n",
      "where M(σ) is the maximum likelihood language model. The choice of a value for β might be\n",
      "based on characteristics of the existing text. For example, we might guess that β should be\n",
      "roughly half of the probability of a unique term in the existing text:\n",
      "β = 0.5 ·\n",
      "1\n",
      "\u0003\n",
      "σ′∈V frequency(σ′) .\n",
      "(1.8)\n",
      "Fortunately, out-of-vocabulary terms are not usually a problem in IR systems because the\n",
      "complete vocabulary of the collection may be determined during the indexing process.\n",
      "1.3\n",
      "Working with Electronic Text\n",
      "19\n",
      "Index and text compression (Chapter 6) represents another important area for the application\n",
      "of language models. When used in compression algorithms, the terms in the vocabulary are\n",
      "usually individual characters or bits rather than entire words. Language modeling approaches\n",
      "that were invented in the context of compression are usually calledcompression models, and\n",
      "this terminology is common in the literature. However, compression models are just specialized\n",
      "language models. In Chapter 10, compression models are applied to the problem of detecting\n",
      "e-mail spam and other ﬁltering problems.\n",
      "Language models may be used to generate text, as well as to predict unseen text. For example,\n",
      "we may produce “random Shakespeare” by randomly generating a sequence of terms based on\n",
      "the probability distribution M(σ):\n",
      "strong die hat circumstance in one eyes odious love to our the wrong wailful would all\n",
      "sir you to babies a in in of er immediate slew let on see worthy all timon nourish both\n",
      "my how antonio silius my live words our my ford scape\n",
      "Higher-order models\n",
      "The random text shown above does not read much like Shakespeare, or even like English text\n",
      "written by lesser authors. Because each term is generated in isolation, the probability of gener-\n",
      "ating the word “the” immediately after generating “our” remains at 3.1%. In real English text,\n",
      "the possessive adjective “our” is almost always followed by a common noun. Even though the\n",
      "phrase “our the” consists of two frequently occurring words, it rarely occurs in English, and\n",
      "never in Shakespeare.\n",
      "Higher-order language models allow us to take this context into account. A ﬁrst-order language\n",
      "model consists of conditional probabilities that depend on the previous symbol. For example:\n",
      "M1(σ2 |σ1) =\n",
      "frequency(σ1σ2)\n",
      "\u0003\n",
      "σ′∈V frequency(σ1σ′) .\n",
      "(1.9)\n",
      "A ﬁrst-order language model for terms is equivalent to the zero-order model for term bigrams\n",
      "estimated using the same technique (e.g., MLE):\n",
      "M1(σ2 |σ1) =\n",
      "M0(σ1σ2)\n",
      "\u0003\n",
      "σ′∈V M0(σ1σ′) .\n",
      "(1.10)\n",
      "More generally, every nth-order language model may be expressed in terms of a zero-order\n",
      "(n + 1)-gram model:\n",
      "Mn(σn+1 |σ1 . . . σn) =\n",
      "M0(σ1 . . . σn+1)\n",
      "\u0003\n",
      "σ′∈V M0(σ1 . . . σn σ′) .\n",
      "(1.11)\n",
      "As an example, consider the phrase “ﬁrst witch” in Shakespeare’s plays. This phrase appears\n",
      "a total of 23 times, whereas the term “ﬁrst” appears 1,349 times. The maximum likelihood\n",
      "Chapter 1\n",
      "Introduction\n",
      "20\n",
      "bigram model thus assigns the following probability:\n",
      "M0(“ﬁrst witch”) =\n",
      "23\n",
      "912,051 ≈0.0025%\n",
      "(note that the denominator is 912,051, not 912,052, because the total number of bigrams is one\n",
      "less than the total number of tokens). The corresponding probability in the ﬁrst-order model is\n",
      "M1(“witch”|“ﬁrst”) =\n",
      "23\n",
      "1349 ≈1.7%.\n",
      "Using Equations 1.9 and 1.10, and ignoring the diﬀerence between the number of tokens and\n",
      "the number of bigrams, the maximum likelihood estimate for “our the” is\n",
      "M0(“our the”) = M0(“our”) · M1(“the”|“our”) = 0%,\n",
      "which is what we would expect, because the phrase never appears in the text. Unfortunately,\n",
      "the model also assigns a zero probability to more reasonable bigrams that do not appear in\n",
      "Shakespeare, such as “fourth witch”. Because “fourth” appears 55 times and “witch” appears\n",
      "92 times, we can easily imagine that an unknown play might contain this bigram. Moreover, we\n",
      "should perhaps assign a small positive probability to bigrams such as “our the” to accommodate\n",
      "unusual usage, including archaic spellings and accented speech. For example, The Merry Wives\n",
      "of Windsor contains the apparently meaningless bigram “a the” in a speech by the French\n",
      "physician Doctor Caius: “If dere be one or two, I shall make-a the turd.” Once more context is\n",
      "seen, the meaning becomes clearer.\n",
      "Smoothing\n",
      "One solution to this problem is to smooth the ﬁrst-order model M1 with the corresponding\n",
      "zero-order model M0. Our smoothed model M′\n",
      "1 is then a linear combination of M0 and M1:\n",
      "M′\n",
      "1(σ2 |σ1) = γ · M1(σ2 |σ1) + (1 −γ) · M0(σ2)\n",
      "(1.12)\n",
      "and equivalently\n",
      "M′\n",
      "0(σ1σ2) = γ · M0(σ1σ2) + (1 −γ) · M0(σ1) · M0(σ2),\n",
      "(1.13)\n",
      "where γ in both cases is a smoothing parameter (0 ≤γ ≤1). For example, using maximum\n",
      "likelihood estimates and setting γ = 0.5, we have\n",
      "M′\n",
      "0(“ﬁrst witch”)\n",
      "=\n",
      "γ · M0(“ﬁrst witch”) + (1 −γ) · M0(“ﬁrst”) · M0(“witch”)\n",
      "=\n",
      "0.5 ·\n",
      "23\n",
      "912, 051 + 0.5 ·\n",
      "1, 349\n",
      "912, 052 ·\n",
      "92\n",
      "912, 052 ≈0.0013%\n",
      "1.3\n",
      "Working with Electronic Text\n",
      "21\n",
      "\u0002\n",
      "\u0003\n",
      "\u0004\n",
      "\u0005\n",
      "\u0006\t\n",
      "\u000b\f\u0004\u000b\n",
      "\u0006\u0007\t\n",
      "\u000b\f\u000e\u000b\n",
      "\u0006\u000f\u0010\t\n",
      "\u000b\f\u0005\u000b\n",
      "\u0006\u0007\t\n",
      "\u000b\f\u0011\u000b\n",
      "\u0012\t\n",
      "\u000b\f\u0003\u000b\n",
      "\u0006\t\n",
      "\u000b\f\u0013\u000b\n",
      "\u0006\u0007\t\n",
      "\u000b\f\u0002\u000b\n",
      "\u0006\u000f\u0010\t\n",
      "\u000b\f\u0014\u000b\n",
      "Figure 1.6\n",
      "A Markov model.\n",
      "and\n",
      "M′\n",
      "0(“fourth witch”)\n",
      "=\n",
      "γ · M0(“fourth witch”) + (1 −γ) · M0(“fourth”) · M0(“witch”)\n",
      "=\n",
      "0.5 ·\n",
      "0\n",
      "912,051 + 0.5 ·\n",
      "55\n",
      "912,052 ·\n",
      "92\n",
      "912,052 ≈0.00000030%.\n",
      "First-order models can be smoothed using zero-order models; second-order models can be\n",
      "smoothed using ﬁrst-order models; and so forth. Obviously, for zero-order models, this approach\n",
      "does not work. However, we can follow the same approach that we used to address out-of-\n",
      "vocabulary terms (Equation 1.5). Alternatively (and more commonly), the zero-order model\n",
      "MS,0 for a small collection S can be smoothed using another zero-order model, built from a\n",
      "larger collection L:\n",
      "M′\n",
      "S,0 = γ · MS,0 + (1 −γ) · ML,0 ,\n",
      "(1.14)\n",
      "where L could be an arbitrary (but large) corpus of English text.\n",
      "Markov models\n",
      "Figure 1.6 illustrates a Markov model, another important method for representing term dis-\n",
      "tributions. Markov models are essentially ﬁnite-state automata augmented with transition\n",
      "probabilities. When used to express a language model, each transition is labeled with a term, in\n",
      "addition to the probability. Following a transition corresponds to predicting or generating that\n",
      "term. Starting in state 1, we may generate the string “to be or not to be” by following the state\n",
      "sequence 1 →2 →3 →4 →1 →2 →3, with the associated probability\n",
      "0.40 × 0.30 × 0.20 × 0.10 × 0.40 × 0.30 = 0.029%.\n",
      "Chapter 1\n",
      "Introduction\n",
      "22\n",
      "Missing transitions (e.g., between state 1 and state 4) are equivalent to transitions with zero\n",
      "probability. Because these transitions will never be taken, it is pointless to associate a term\n",
      "with them. For simplicity, we also assume that there is at most one transition between any two\n",
      "states. We do not sacriﬁce anything by making this simpliﬁcation. For any Markov model with\n",
      "multiple transitions between the same pair of states, there is a corresponding model without\n",
      "them (see Exercise 1.7).\n",
      "The probability predicted by a Markov model depends on the starting state. Starting in\n",
      "state 4, the probability of generating “to be or not to be” is\n",
      "0.90 × 0.30 × 0.20 × 0.10 × 0.40 × 0.30 = 0.065%.\n",
      "Markov models form the basis for a text compression model introduced for ﬁltering in\n",
      "Chapter 10.\n",
      "We may represent a Markov model with n states as an n×n transition matrix M, where M[i][j]\n",
      "gives the probability of a transition from state i to state j. The transition matrix corresponding\n",
      "to the Markov model in Figure 1.6 is\n",
      "M =\n",
      "⎛\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎝\n",
      "0.00\n",
      "0.40\n",
      "0.00\n",
      "0.60\n",
      "0.70\n",
      "0.00\n",
      "0.30\n",
      "0.00\n",
      "0.00\n",
      "0.80\n",
      "0.00\n",
      "0.20\n",
      "0.10\n",
      "0.90\n",
      "0.00\n",
      "0.00\n",
      "⎞\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎠\n",
      ".\n",
      "(1.15)\n",
      "Note that all of the values in the matrix fall in the range [0, 1] and that each row of M sums to\n",
      "1. An n × n matrix with these properties is known as a stochastic matrix.\n",
      "Given a transition matrix, we can compute the outcome of a transition by multiplying the\n",
      "transition matrix by a state vector representing the current state. For example, we can represent\n",
      "an initial start state of 1 by the vector (1 0 0 0). After one step, we have\n",
      "\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "\u000b\n",
      "⎛\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎝\n",
      "0.00\n",
      "0.40\n",
      "0.00\n",
      "0.60\n",
      "0.70\n",
      "0.00\n",
      "0.30\n",
      "0.00\n",
      "0.00\n",
      "0.80\n",
      "0.00\n",
      "0.20\n",
      "0.10\n",
      "0.90\n",
      "0.00\n",
      "0.00\n",
      "⎞\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎠\n",
      "=\n",
      "\n",
      "0.00\n",
      "0.40\n",
      "0.00\n",
      "0.60\n",
      "\u000b\n",
      ".\n",
      "That is, after one step, the probability of being in state 2 is 0.40 and the probability of being\n",
      "in state 4 is 0.60, as expected. Multiplying again, we have\n",
      "\n",
      "0.00\n",
      "0.40\n",
      "0.00\n",
      "0.60\n",
      "\u000b\n",
      "⎛\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎜\n",
      "⎝\n",
      "0.00\n",
      "0.40\n",
      "0.00\n",
      "0.60\n",
      "0.70\n",
      "0.00\n",
      "0.30\n",
      "0.00\n",
      "0.00\n",
      "0.80\n",
      "0.00\n",
      "0.20\n",
      "0.10\n",
      "0.90\n",
      "0.00\n",
      "0.00\n",
      "⎞\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎟\n",
      "⎠\n",
      "=\n",
      "\n",
      "0.34\n",
      "0.54\n",
      "0.12\n",
      "0.00\n",
      "\u000b\n",
      ".\n",
      "1.4\n",
      "Test Collections\n",
      "23\n",
      "This result tells us, for example, that the probability of being in state 2 after two steps is\n",
      "0.54. In general, the state vector may be any n-dimensional vector whose elements sum to 1.\n",
      "Multiplying the state vector by the transition matrix k times gives the probability of being in\n",
      "each state after k steps.\n",
      "A stochastic matrix together with an initial state vector is known as a Markov chain. Markov\n",
      "chains are used in the presentation of Web link analysis algorithms in Chapter 15. Markov\n",
      "chains — and by extension Markov models — are named after the Russian statistician Andrey\n",
      "Markov (1856–1922), who stated and proved many of their properties.\n",
      "1.4\n",
      "Test Collections\n",
      "Although Macbeth and Shakespeare’s other plays provide an excellent source of examples for\n",
      "simple IR concepts, researchers have developed more substantial test collections for evaluation\n",
      "purposes. Many of these collections have been created as part of TREC2 (Text REtrieval Con-\n",
      "ference), a series of experimental evaluation eﬀorts conducted annually since 1991 by the U.S.\n",
      "National Institute of Standards and Technology (NIST). TREC provides a forum for researchers\n",
      "to test their IR systems on a broad range of problems. For example, more than 100 groups from\n",
      "universities, industry, and government participated in TREC 2007.\n",
      "In a typical year, TREC experiments are structured into six or seven tracks, each devoted\n",
      "to a diﬀerent area of information retrieval. In recent years, TREC has included tracks devoted\n",
      "to enterprise search, genomic information retrieval, legal discovery, e-mail spam ﬁltering, and\n",
      "blog search. Each track is divided into several tasks that test diﬀerent aspects of that area. For\n",
      "example, at TREC 2007, the enterprise search track included an e-mail discussion search task\n",
      "and a task to identify experts on given topics. A track typically operates for three or more years\n",
      "before being retired.\n",
      "TREC provides at least two important beneﬁts to the IR community. First, it focuses\n",
      "researchers on common problems, using common data, thus providing a forum for them to\n",
      "present and discuss their work and facilitating direct inter-system comparisons. What works\n",
      "and what does not work can be determined quickly. As a result, considerable progress and sub-\n",
      "stantial performance improvements are often seen immediately following the introduction of a\n",
      "new track into TREC. As a second beneﬁt, TREC aims to create reusable test collections that\n",
      "can be used by participating groups to validate further improvements and by non-participating\n",
      "groups to evaluate their own work. In addition, since its inception, TREC has formed the\n",
      "inspiration for a number of similar experimental eﬀorts throughout the world. These include\n",
      "the European INEX eﬀort for XML retrieval, the CLEF eﬀort for multi-lingual information\n",
      "retrieval, the Japanese NTCIR eﬀort for Asian language information retrieval, and the Indian\n",
      "FIRE eﬀort.\n",
      "2 trec.nist.gov\n",
      "Chapter 1\n",
      "Introduction\n",
      "24\n",
      "<DOC>\n",
      "<DOCNO> LA051990-0141 </DOCNO>\n",
      "<HEADLINE> COUNCIL VOTES TO EDUCATE DOG OWNERS </HEADLINE>\n",
      "<P>\n",
      "The City Council stepped carefully around enforcement of a dog-curbing\n",
      "ordinance this week, vetoing the use of police to enforce the law.\n",
      "</P>\n",
      ". . .\n",
      "</DOC>\n",
      "Figure 1.7\n",
      "Example TREC document (LA051990-0141) from disk 5 of the TREC CDs.\n",
      "1.4.1\n",
      "TREC Tasks\n",
      "Basic search tasks — in which systems return a ranked list from a static set of documents using\n",
      "previously unseen topics — are referred to as “adhoc” tasks in TREC jargon (often written as\n",
      "one word). Along with a set of documents, a test collection for an adhoc task includes sets of\n",
      "topics, from which queries may be created, and sets of relevance judgments (known as “qrel\n",
      "ﬁles” or just “qrels”), indicating documents that are relevant or not relevant to each topic. Over\n",
      "the history of TREC, adhoc tasks have been a part of tracks with a number of diﬀerent research\n",
      "themes, such as Web retrieval or genomic IR. Despite diﬀerences in themes, the organization and\n",
      "operation of an adhoc task is basically the same across the tracks and is essentially unchanged\n",
      "since the earliest days of TREC.\n",
      "Document sets for older TREC adhoc tasks (before 2000) were often taken from a set of 1.6\n",
      "million documents distributed to TREC participants on ﬁve CDs. These disks contain selections\n",
      "of newspaper and newswire articles from publications such as the Wall Street Journal and the LA\n",
      "Times, and documents published by the U.S. federal government, such as the Federal Register\n",
      "and the Congressional Record. Most of these documents are written and edited by professionals\n",
      "reporting factual information or describing events.\n",
      "Figure 1.7 shows a short excerpt from a document on disk 5 of the TREC CDs. The docu-\n",
      "ment appeared as a news article in the LA Times on May 19, 1990. For the purposes of TREC\n",
      "experiments, it is marked up in the style of XML. Although the details of the tagging schemes\n",
      "vary across the TREC collections, all TREC documents adhere to the same tagging convention\n",
      "for identifying document boundaries and document identiﬁers. Every TREC document is sur-\n",
      "rounded by <DOC>...</DOC> tags; <DOCNO>...</DOCNO> tags indicate its unique identiﬁer. This\n",
      "identiﬁer is used in qrels ﬁles when recording judgments for the document. This convention\n",
      "simpliﬁes the indexing process and allows collections to be combined easily. Many research IR\n",
      "systems provide out-of-the-box facilities for working with documents that follow this convention.\n",
      "1.4\n",
      "Test Collections\n",
      "25\n",
      "<top>\n",
      "<num> Number: 426\n",
      "<title> law enforcement, dogs\n",
      "<desc> Description:\n",
      "Provide information on the use of dogs worldwide for\n",
      "law enforcement purposes.\n",
      "<narr> Narrative:\n",
      "Relevant items include specific information on the\n",
      "use of dogs during an operation. Training of dogs\n",
      "and their handlers are also relevant.\n",
      "</top>\n",
      "Figure 1.8\n",
      "TREC topic 426.\n",
      "Document sets for newer TREC adhoc tasks are often taken from the Web. Until 2009, the\n",
      "largest of these was the 426GB GOV2 collection, which contains 25 million Web pages crawled\n",
      "from sites in the U.S. government’s gov domain in early 2004. This crawl attempted to reach as\n",
      "many pages as possible within the gov domain, and it may be viewed as a reasonable snapshot\n",
      "of that domain within that time period. GOV2 contains documents in a wide variety of formats\n",
      "and lengths, ranging from lengthy technical reports in PDF to pages of nothing but links in\n",
      "HTML. GOV2 formed the document set for the Terabyte Track from TREC 2004 until the track\n",
      "was discontinued at the end of 2006. It also formed the collection for the Million Query Track\n",
      "at TREC 2007 and 2008.\n",
      "Although the GOV2 collection is substantially larger than any previous TREC collection, it\n",
      "is still orders of magnitude smaller than the collections managed by commercial Web search\n",
      "engines. TREC 2009 saw the introduction of a billion-page Web collection, known as the\n",
      "ClueWeb09 collection, providing an opportunity for IR researchers to work on a scale comparable\n",
      "to commercial Web search.3\n",
      "For each year that a track operates an adhoc task, NIST typically creates 50 new topics.\n",
      "Participants are required to freeze development of their systems before downloading these topics.\n",
      "After downloading the topics, participants create queries from them, run these queries against\n",
      "the document set, and return ranked lists to NIST for evaluation.\n",
      "A typical TREC adhoc topic, created for TREC 1999, is shown in Figure 1.8. Like most\n",
      "TREC topics, it is structured into three parts, describing the underlying information need in\n",
      "several forms. The title ﬁeld is designed to be treated as a keyword query, similar to a query\n",
      "that might be entered into a search engine. The description ﬁeld provides a longer statement\n",
      "of the topic requirements, in the form of a complete sentence or question. It, too, may be used\n",
      "3 boston.lti.cs.cmu.edu/Data/clueweb09\n",
      "Chapter 1\n",
      "Introduction\n",
      "26\n",
      "Table 1.2\n",
      "Summary of the test collections used for many of the experiments\n",
      "described in this book.\n",
      "Document Set\n",
      "Number of Docs\n",
      "Size (GB)\n",
      "Year\n",
      "Topics\n",
      "TREC45\n",
      "0.5 million\n",
      "2\n",
      "1998\n",
      "351–400\n",
      "1999\n",
      "401–450\n",
      "GOV2\n",
      "25.2 million\n",
      "426\n",
      "2004\n",
      "701–750\n",
      "2005\n",
      "751–800\n",
      "as a query, particularly by research systems that apply natural language processing techniques\n",
      "as part of retrieval. The narrative, which may be a full paragraph in length, supplements the\n",
      "other two ﬁelds and provides additional information required to specify the nature of a relevant\n",
      "document. The narrative ﬁeld is primarily used by human assessors, to help determine if a\n",
      "retrieved document is relevant or not.\n",
      "Most retrieval experiments in this book report results over four TREC test collections based\n",
      "on two document sets, a small one and a larger one. The small collection consists of the doc-\n",
      "uments from disks 4 and 5 of the TREC CDs described above, excluding the documents from\n",
      "the Congressional Record. It includes documents from the Financial Times, the U.S. Federal\n",
      "Register, the U.S. Foreign Broadcast Information Service, and the LA Times. This document\n",
      "set, which we refer to as TREC45, was used for the main adhoc task at TREC 1998 and 1999.\n",
      "In both 1998 and 1999, NIST created 50 topics with associated relevance judgments over\n",
      "this document set. The 1998 topics are numbered 351–400; the 1999 topics are numbered 401–\n",
      "450. Thus, we have two test collections over the TREC45 document set, which we refer to as\n",
      "TREC45 1998 and TREC45 1999. Although there are minor diﬀerences between our experi-\n",
      "mental procedure and that used in the corresponding TREC experiments (which we will ignore),\n",
      "our experimental results reported over these collections may reasonably be compared with the\n",
      "published results at TREC 1998 and 1999.\n",
      "The larger one of the two document sets used in our experiments is the GOV2 corpus men-\n",
      "tioned previously. We take this set together with topics and judgments from the TREC Terabyte\n",
      "track in 2004 (topics 701–750) and 2005 (751–800) to form the GOV2 2004 and GOV2 2005\n",
      "collections. Experimental results reported over these collections may reasonably be compared\n",
      "with the published results for the Terabyte track of TREC 2004 and 2005.\n",
      "Table 1.2 summarizes our four test collections. The TREC45 collection may be obtained\n",
      "from the NIST Standard Reference Data Products Web page as Special Databases 22 and 23.4\n",
      "The GOV2 collection is distributed by the University of Glasgow.5 Topics and qrels for these\n",
      "collections may be obtained from the TREC data archive.6\n",
      "4 www.nist.gov/srd\n",
      "5 ir.dcs.gla.ac.uk/test collections\n",
      "6 trec.nist.gov\n",
      "1.5\n",
      "Open-Source IR Systems\n",
      "27\n",
      "1.5\n",
      "Open-Source IR Systems\n",
      "There exists a wide variety of open-source information retrieval systems that you may use for\n",
      "exercises in this book and to start conducting your own information retrieval experiments. As\n",
      "always, a (non-exhaustive) list of open-source IR systems can be found in Wikipedia.7\n",
      "Since this list of available systems is so long, we do not even try to cover it in detail. Instead,\n",
      "we restrict ourselves to a very brief overview of three particular systems that were chosen\n",
      "because of their popularity, their inﬂuence on IR research, or their intimate relationship with\n",
      "the contents of this book. All three systems are available for download from the Web and may\n",
      "be used free of charge, according to their respective licenses.\n",
      "1.5.1\n",
      "Lucene\n",
      "Lucene is an indexing and search system implemented in Java, with ports to other programming\n",
      "languages. The project was started by Doug Cutting in 1997. Since then, it has grown from a\n",
      "single-developer eﬀort to a global project involving hundreds of developers in various countries.\n",
      "It is currently hosted by the Apache Foundation.8 Lucene is by far the most successful open-\n",
      "source search engine. Its largest installation is quite likely Wikipedia: All queries entered into\n",
      "Wikipedia’s search form are handled by Lucene. A list of other projects relying on its indexing\n",
      "and search capabilities can be found on Lucene’s “PoweredBy” page.9\n",
      "Known for its modularity and extensibility, Lucene allows developers to deﬁne their own\n",
      "indexing and retrieval rules and formulae. Under the hood, Lucene’s retrieval framework is\n",
      "based on the concept of ﬁelds: Every document is a collection of ﬁelds, such as its title, body,\n",
      "URL, and so forth. This makes it easy to specify structured search requests and to give diﬀerent\n",
      "weights to diﬀerent parts of a document.\n",
      "Due to its great popularity, there is a wide variety of books and tutorials that help you get\n",
      "started with Lucene quickly. Try the query “lucene tutorial” in your favorite Web search engine.\n",
      "1.5.2\n",
      "Indri\n",
      "Indri10 is an academic information retrieval system written in C++. It is developed by\n",
      "researchers at the University of Massachusetts and is part of the Lemur project,11 a joint\n",
      "eﬀort of the University of Massachusetts and Carnegie Mellon University.\n",
      "7 en.wikipedia.org/wiki/List of search engines\n",
      "8 lucene.apache.org\n",
      "9 wiki.apache.org/lucene-java/PoweredBy\n",
      "10 www.lemurproject.org/indri/\n",
      "11 www.lemurproject.org\n",
      "Chapter 1\n",
      "Introduction\n",
      "28\n",
      "Indri is well known for its high retrieval eﬀectiveness and is frequently found among the top-\n",
      "scoring search engines at TREC. Its retrieval model is a combination of the language modeling\n",
      "approaches discussed in Chapter 9. Like Lucene, Indri can handle multiple ﬁelds per docu-\n",
      "ment, such as title, body, and anchor text, which is important in the context of Web search\n",
      "(Chapter 15). It supports automatic query expansion by means of pseudo-relevance feedback, a\n",
      "technique that adds related terms to an initial search query, based on the contents of an initial\n",
      "set of search results (see Section 8.6). It also supports query-independent document scoring that\n",
      "may, for instance, be used to prefer more recent documents over less recent ones when ranking\n",
      "the search results (see Sections 9.1 and 15.3).\n",
      "1.5.3\n",
      "Wumpus\n",
      "Wumpus12 is an academic search engine written in C++ and developed at the University of\n",
      "Waterloo. Unlike most other search engines, Wumpus has no built-in notion of “documents”\n",
      "and does not know about the beginning and the end of each document when it builds the index.\n",
      "Instead, every part of the text collection may represent a potential unit for retrieval, depending\n",
      "on the structural search constraints speciﬁed in the query. This makes the system particularly\n",
      "attractive for search tasks in which the ideal search result may not always be a whole document,\n",
      "but may be a section, a paragraph, or a sequence of paragraphs within a document.\n",
      "Wumpus supports a variety of diﬀerent retrieval methods, including the proximity ranking\n",
      "function from Chapter 2, the BM25 algorithm from Chapter 8, and the language modeling and\n",
      "divergence from randomness approaches discussed in Chapter 9. In addition, it is able to carry\n",
      "out real-time index updates (i.e., adding/removing ﬁles to/from the index) and provides support\n",
      "for multi-user security restrictions that are useful if the system has more than one user, and\n",
      "each user is allowed to search only parts of the index.\n",
      "Unless explicitly stated otherwise, all performance ﬁgures presented in this book were obtained\n",
      "using Wumpus.\n",
      "1.6\n",
      "Further Reading\n",
      "This is not the ﬁrst book on the topic of information retrieval. Of the older books providing\n",
      "a general introduction to IR, several should be mentioned. The classic books by Salton (1968)\n",
      "and van Rijsbergen (1979) continue to provide insights into the foundations of the ﬁeld. The\n",
      "treatment of core topics given by Grossman and Frieder (2004) remains relevant. Witten et al.\n",
      "(1999) provide background information on many related topics that we do not cover in this\n",
      "book, including text and image compression.\n",
      "12 www.wumpus-search.org\n",
      "1.6\n",
      "Further Reading\n",
      "29\n",
      "Several good introductory texts have appeared in recent years. The textbook by Croft et al.\n",
      "(2010) is intended to give an undergraduate-level introduction to the area. Baeza-Yates and\n",
      "Ribeiro-Neto (2010) provide a broad survey of the ﬁeld, with experts contributing individual\n",
      "chapters on their areas of expertise. Manning et al. (2008) provide another readable survey.\n",
      "Survey articles on speciﬁc topics appear regularly as part of the journal series Foundations\n",
      "and Trends in Information Retrieval. The Encyclopedia of Database Systems (¨Ozsu and Liu,\n",
      "2009) contains many introductory articles on topics related to information retrieval. Hearst\n",
      "(2009) provides an introduction to user interface design for information retrieval applications.\n",
      "The ﬁeld of natural language processing, particularly the sub-ﬁeld of statistical natural language\n",
      "processing, is closely related to the ﬁeld of information retrieval. Manning and Sch¨utze (1999)\n",
      "provide a thorough introduction to that area.\n",
      "The premier research conference in the area is the Annual International ACM SIGIR Confer-\n",
      "ence on Research and Development in Information Retrieval (SIGIR), now well into its fourth\n",
      "decade. Other leading research conferences and workshops include the ACM Conference on\n",
      "Information and Knowledge Management (CIKM), the Joint Conference on Digital Libraries\n",
      "(JCDL), the European Conference on Information Retrieval (ECIR), the ACM International\n",
      "Conference on Web Search and Data Mining (WSDM), the conference on String Processing and\n",
      "Information Retrieval (SPIRE), and the Text REtrieval Conference (TREC). Important IR\n",
      "research also regularly appears in the premier venues of related ﬁelds, such as the World Wide\n",
      "Web Conference (WWW), the Annual Conference on Neural Information Processing Systems\n",
      "(NIPS), the Conference on Artiﬁcial Intelligence (AAAI), and the Knowledge Discovery and\n",
      "Data Mining Conference (KDD). The premier IR journal is ACM Transactions on Information\n",
      "Systems. Other leading journals include Information Retrieval and the venerable Information\n",
      "Processing & Management.\n",
      "Many books and Web sites devoted to learning and using XML are available. One important\n",
      "resource is the XML home page of the World Wide Web Consortium (W3C),13 the organization\n",
      "responsible for deﬁning and maintaining the XML technical speciﬁcation. Along with exten-\n",
      "sive reference materials, the site includes pointers to introductory tutorials and guides. Jon\n",
      "Bosak’s personal Web page14 contains many articles and other information related to the early\n",
      "development and usage of XML, including Shakespeare’s plays.\n",
      "13 www.w3.org/XML/\n",
      "14 www.ibiblio.org/bosak\n",
      "Chapter 1\n",
      "Introduction\n",
      "30\n",
      "1.7\n",
      "Exercises\n",
      "Exercise 1.1\n",
      "Record the next ten queries you issue to a Web search engine (or check your\n",
      "Web history if your search engine allows it). Note how many are reﬁnements of previous queries,\n",
      "adding or removing terms to narrow or broaden the focus of the query. Choose three commercial\n",
      "search engines, including the engine you normally use, and reissue the queries on all three. For\n",
      "each query, examine the top ﬁve results from each engine. For each result, rate on it a scale from\n",
      "-10 to +10, where +10 represents a perfect or ideal result and -10 represents a misleading or\n",
      "harmful result (spam). Compute an average score for each engine over all ten queries and results.\n",
      "Did the engine you normally use receive the highest score? Do you believe that the results of\n",
      "this exercise accurately reﬂect the relative quality of the search engines? Suggest three possible\n",
      "improvements to this experiment.\n",
      "Exercise 1.2\n",
      "Obtain and install an open-source IR system, such as one of those listed in\n",
      "Section 1.5. Create a small document collection from your e-mail, or from another source. A\n",
      "few dozen documents should be enough. Index your collection. Try a few queries.\n",
      "Exercise 1.3\n",
      "Starting in state 3 of the Markov model in Figure 1.6, what is the probability\n",
      "of generating “not not be to be”?\n",
      "Exercise 1.4\n",
      "Starting in an unknown state, the Markov model in Figure 1.6 generates “to\n",
      "be”. What state or states could be the current state of the model after generating this text?\n",
      "Exercise 1.5\n",
      "Is there a ﬁnite n, such that the current state of the Markov model in Figure 1.6\n",
      "will always be known after it generates a string of length n or greater, regardless of the starting\n",
      "state?\n",
      "Exercise 1.6\n",
      "For a given Markov model, assume there is a ﬁnite n so that the current state\n",
      "of the model will always be known after it generates a string of length n or greater. Describe a\n",
      "procedure for converting such a Markov model into an nth-order ﬁnite-context model.\n",
      "Exercise 1.7\n",
      "Assume that we extend Markov models to allow multiple transitions between\n",
      "pairs of states, where each transition between a given pair of states is labeled with a diﬀerent\n",
      "term. For any such model, show that there is an equivalent Markov model in which there is no\n",
      "more than one transition between any pair of states. (Hint: Split target states.)\n",
      "Exercise 1.8\n",
      "Outline a procedure for converting an nth-order ﬁnite-context language model\n",
      "into a Markov model. How many states might be required?\n",
      "1.7\n",
      "Exercises\n",
      "31\n",
      "Exercise 1.9 (project exercise)\n",
      "This exercise develops a test corpus, based on Wikipedia,\n",
      "that will be used in a number of exercises throughout Part I.\n",
      "To start, download a current copy of the English-language Wikipedia. At the time of writing,\n",
      "its downloadable version consisted of a single large ﬁle. Wikipedia itself contains documentation\n",
      "describing the format of this download.15\n",
      "Along with the text of the articles themselves, the download includes redirection records that\n",
      "provide alternative titles for articles. Pre-process the download to remove these records and any\n",
      "other extraneous information, leaving a set of individual articles. Wikipedia-style formatting\n",
      "should also be removed, or replaced with XML-style tags of your choosing. Assign a unique\n",
      "identiﬁer to each article. Add <DOC> and <DOCNO> tags. The result should be consistent\n",
      "with TREC conventions, as described in Section 1.4 and illustrated in Figure 1.7.\n",
      "Exercise 1.10 (project exercise)\n",
      "Following the style of Figure 1.8, create three to four\n",
      "topics suitable for testing retrieval performance over the English-language Wikipedia. Try to\n",
      "avoid topics expressing an information need that can be completely satisﬁed by a single “best”\n",
      "article. Instead, try to create topics that require multiple articles in order to cover all relevant\n",
      "information. (Note: This exercise is suitable as the foundation for a class project to create a\n",
      "Wikipedia test collection, with each student contributing enough topics to make a combined set\n",
      "of 50 topics or more. (See Exercise 2.13 for further details.)\n",
      "Exercise 1.11 (project exercise)\n",
      "Obtain and install an open-source IR system (see Exer-\n",
      "cise 1.2). Using this IR system, index the collection you created in Exercise 1.9. Submit the\n",
      "titles of the topics you created in Exercise 1.10 as queries to the system. For each topic, judge\n",
      "the top ﬁve documents returned as either relevant or not. Does the IR system work equally well\n",
      "on all topics?\n",
      "Exercise 1.12 (project exercise)\n",
      "Tokenize the collection you created in Exercise 1.9, fol-\n",
      "lowing the procedure of Section 1.3.2. For this exercise, discard the tags and keep only the\n",
      "words (i.e., strings of alphanumeric characters). Wikipedia text is encoded in UTF-8 Unicode,\n",
      "but you may treat it as ASCII text for the purpose of this exercise. Generate a log-log plot of\n",
      "frequency vs. rank order, equivalent to that shown in Figure 1.5. Does the data follow Zipf’s\n",
      "law? If so, what is an approximate value for α?\n",
      "Exercise 1.13 (project exercise)\n",
      "Create a trigram language model based on the tokeniza-\n",
      "tion of Exercise 1.12. Using your language model, implement a random Wikipedia text generator.\n",
      "How could you extend your text generator to generate capitalization and punctuation, making\n",
      "your text look more like English? How could you extend your text generator to generate random\n",
      "Wikipedia articles, including tagging and links?\n",
      "15 en.wikipedia.org/wiki/Wikipedia:Database download\n",
      "Chapter 1\n",
      "Introduction\n",
      "32\n",
      "1.8\n",
      "Bibliography\n",
      "Baeza-Yates, R. A., and Ribeiro-Neto, B. (2010).\n",
      "Modern Information Retrieval (2nd ed.).\n",
      "Reading, Massachusetts: Addison-Wesley.\n",
      "Croft, W. B., Metzler, D., and Strohman, T. (2010). Search Engines: Information Retrieval in\n",
      "Practice. London, England: Pearson.\n",
      "Grossman, D. A., and Frieder, O. (2004). Information Retrieval: Algorithms and Heuristics\n",
      "(2nd ed.). Berlin, Germany: Springer.\n",
      "Hearst, M. A. (2009). Search User Interfaces. Cambridge, England: Cambridge University Press.\n",
      "Manning, C. D., Raghavan, P., and Sch¨utze, H. (2008). Introduction to Information Retrieval.\n",
      "Cambridge, England: Cambridge University Press.\n",
      "Manning, C. D., and Sch¨utze, H. (1999). Foundations of Statistical Natural Language Processing.\n",
      "Cambridge, Massachusetts: MIT Press.\n",
      "¨Ozsu, M. T., and Liu, L., editors (2009). Encyclopedia of Database Systems. Berlin, Germany:\n",
      "Springer.\n",
      "Salton, G. (1968). Automatic Information Organziation and Retrieval. New York: McGraw-Hill.\n",
      "van Rijsbergen, C. J. (1979). Information Retrieval (2nd ed.). London, England: Butterworths.\n",
      "Witten, I. H., Moﬀat, A., and Bell, T. C. (1999).\n",
      "Managing Gigabytes: Compressing and\n",
      "Indexing Documents and Images (2nd ed.). San Francisco, California: Morgan Kaufmann.\n",
      "Zipf, G. K. (1949).\n",
      "Human Behavior and the Principle of Least-Eﬀort.\n",
      "Cambridge, Mas-\n",
      "sachusetts: Addison-Wesley.\n",
      "2\n",
      "Basic Techniques\n",
      "As a foundation for the remainder of the book, this chapter takes a tour through the elements\n",
      "of information retrieval outlined in Chapter 1, covering the basics of indexing, retrieval and\n",
      "evaluation. The material on indexing and retrieval, constituting the ﬁrst two major sections, is\n",
      "closely linked, presenting a uniﬁed view of these topics. The third major section, on evaluation,\n",
      "examines both the eﬃciency and the eﬀectiveness of the algorithms introduced in the ﬁrst two\n",
      "sections.\n",
      "2.1\n",
      "Inverted Indices\n",
      "The inverted index (sometimes called inverted ﬁle) is the central data structure in virtually every\n",
      "information retrieval system. At its simplest, an inverted index provides a mapping between\n",
      "terms and their locations of occurrence in a text collection C. The fundamental components of an\n",
      "inverted index are illustrated in Figure 2.1, which presents an index for the text of Shakespeare’s\n",
      "plays (Figures 1.2 and 1.3). The dictionary lists the terms contained in the vocabulary V of the\n",
      "collection. Each term has associated with it a postings list of the positions in which it appears,\n",
      "consistent with the positional numbering in Figure 1.4 (page 14).\n",
      "If you have encountered inverted indices before, you might be surprised that the index shown\n",
      "in Figure 2.1 contains not document identiﬁers but “ﬂat” word positions of the individual\n",
      "term occurrences. This type of index is called a schema-independent index because it makes no\n",
      "assumptions about the structure (usually referred to as schema in the database community)\n",
      "of the underlying text. We chose the schema-independent variant for most of the examples\n",
      "in this chapter because it is the simplest. An overview of alternative index types appears in\n",
      "Section 2.1.3.\n",
      "Regardless of the speciﬁc type of index that is used, its components — the dictionary and\n",
      "the postings lists — may be stored in memory, on disk, or a combination of both. For now, we\n",
      "keep the precise data structures deliberately vague. We deﬁne an inverted index as an abstract\n",
      "data type (ADT) with four methods:\n",
      "• ﬁrst(t) returns the ﬁrst position at which the term t occurs in the collection;\n",
      "• last(t) returns the last position at which t occurs in the collection;\n",
      "• next(t, current) returns the position of t’s ﬁrst occurrence after the current position;\n",
      "• prev(t, current) returns the position of t’s last occurrence before the current position.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "34\n",
      "\u0002\u0003\u0004\u0005\u0003\u0006\t\n",
      "\f\u000e\u000f\u0003\f\u0005\f\n",
      "\u0002\u0003\u0004\u0005\u0006\u0007\u0007\u0007\n",
      "\b\t\u0004\n",
      "\u000b\f\t\u0004\n",
      "\u000b\u0007\u0007\u0007\n",
      "\u0007\u0007\u0007\n",
      "\u000e\u0004\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u0010\u0004\u0011\u0002\u0006\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u000e\u0005\u0007\u0007\u0007\n",
      "\u0012\u0007\u0007\u0007\n",
      "\u0013\u0015\u0016\u0017\u0018\u0019\u0007\u0007\u0007\n",
      "\u0013\u001a\u0015\u001b\u0017\u001c\u001b\u001d\u0019\u0007\u0007\u0007\n",
      "\u0013\u001a\u0015\u001b\u001b\u001e\u001f\u0019\u0007\u0007\u0007\n",
      "\u0013 \u001a\u0015\u001b\u001b\u001e\u001f\u0019\u0007\u0007\u0007\n",
      "\u0013 \u0015\u0016\u0017\u0018\u0019\u0007\u0007\u0007\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "!!\"#$\u0007!!%&$\u0007'''$\u0007()#)\"%$\u0007()#)%%$\u0007()##\"*$\u0007'''$\u0007*!(*)&(\n",
      "+*%%%,$\u0007()#)+)\n",
      "*($\u0007),$\u0007'''$\u0007()#)*&$\u0007()#)!!$\u0007'''$\u0007*!(*)&\"\n",
      "+%&,&$\u0007*+(!+%$\u0007'''$\u0007()#+,($\u0007()#)*,$\u0007'''$\u0007*!)(*+,\n",
      "*#,&$\u0007!(###$\u0007'''$\u0007()#)\"($\u0007()#)!,$\u0007()#)#*$\u0007()#)%($\u0007'''$\u0007*!)#!(%\n",
      "(*()$\u0007*%#*#\"$\u0007'''$\u0007*!#,)\"%\n",
      "***\"*&$\u0007**,*&+$\u0007'''$\u0007()#)\"!$\u0007'''$\u0007(%!&&+\n",
      "!%#*,(\n",
      "+$\u0007)\"#**$\u0007'''$\u0007*!+)%\"!\n",
      "+*+$\u0007)(!$\u0007'''$\u0007()#)\"#$\u0007()#)!($\u0007()#)),$\u0007()#)%#$\u0007'''$\u0007*!(*!()\n",
      "+*!$\u0007)(*$\u0007'''$\u0007()#)\")$\u0007()#)!%$\u0007()#))&$\u0007()#)%)$\u0007'''$\u0007*!(*!(+\n",
      ")\"#\"&$\u0007(##&\"$\u0007'''$\u0007*!(*#\")\n",
      ")(\"$\u0007)&%$\u0007'''$\u0007()#)!#$\u0007()#))($\u0007()#)%+$\u0007()#)()$\u0007'''$\u0007*!(*),&\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "Figure 2.1\n",
      "A schema-independent inverted index for Shakespeare’s plays. The dictionary provides a\n",
      "mapping from terms to their positions of occurrence.\n",
      "In addition, we deﬁne lt to represent the total number of times the term t appears in the\n",
      "collection (i.e., the length of its postings list). We deﬁne lC to be the length of the collection,\n",
      "so that \u0003\n",
      "t∈V lt = lC (where V is the collection’s vocabulary).\n",
      "For the inverted index in Figure 2.1, we have:\n",
      "ﬁrst(“hurlyburly”) = 316669\n",
      "last(“thunder”) = 1247139\n",
      "ﬁrst(“witching”) = 265197\n",
      "last(“witching”) = 265197\n",
      "2.1\n",
      "Inverted Indices\n",
      "35\n",
      "next(“witch”, 745429) = 745451\n",
      "prev(“witch”, 745451) = 745429\n",
      "next(“hurlyburly”, 345678) = 745434\n",
      "prev(“hurlyburly”, 456789) = 316669\n",
      "next(“witch”, 1245276) = ∞\n",
      "prev(“witch”, 1598) = −∞\n",
      "l<PLAY> = 37\n",
      "lC = 1271504\n",
      "lwitching = 1\n",
      "The symbols −∞and ∞act as beginning-of-ﬁle and end-of-ﬁle markers, representing positions\n",
      "beyond the beginning and the end of the term sequence. As a practical convention we deﬁne:\n",
      "next(t, −∞) = ﬁrst(t)\n",
      "next(t, ∞) = ∞\n",
      "prev(t, ∞) = last(t)\n",
      "prev(t, −∞) = −∞\n",
      "The methods of our inverted index permit both sequential and random access into postings\n",
      "lists, with a sequential scan of a postings list being a simple loop:\n",
      "current ←−∞\n",
      "while current < ∞do\n",
      "current ←next(t, current)\n",
      "do something with the current value\n",
      "However, many algorithms require random access into postings lists, including the phrase search\n",
      "algorithm we present next. Often, these algorithms take the result of a method call for one term\n",
      "and apply it as an argument to a method call for another term, skipping through the postings\n",
      "lists nonsequentially.\n",
      "2.1.1\n",
      "Extended Example: Phrase Search\n",
      "Most commercial Web search engines, as well as many other IR systems, treat a list of terms\n",
      "enclosed in double quotes (\"...\") as a phrase. To process a query that contains a phrase, the IR\n",
      "system must identify the occurrences of the phrase in the collection. This information may then\n",
      "be used during the retrieval process for ﬁltering and ranking — perhaps excluding documents\n",
      "that do not contain an exact phrase match.\n",
      "Phrase search provides an excellent example of how algorithms over inverted indices operate.\n",
      "Suppose we wish to locate all occurrences of the phrase “ﬁrst witch” in our collection of Shake-\n",
      "speare’s plays. Perhaps we wish to identify all speeches by this character. By visually scanning\n",
      "the postings lists in Figure 2.1, we can locate one occurrence starting at 745406 and ending at\n",
      "745407. We might locate other occurrences in a similar fashion by scanning the postings lists\n",
      "for an occurrence of “ﬁrst” immediately followed by an occurrence of “witch”. In this section we\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "36\n",
      "nextPhrase (t1t2...tn, position) ≡\n",
      "1\n",
      "v ←position\n",
      "2\n",
      "for i ←1 to n do\n",
      "3\n",
      "v ←next(ti, v)\n",
      "4\n",
      "if v = ∞then\n",
      "5\n",
      "return [∞, ∞]\n",
      "6\n",
      "u ←v\n",
      "7\n",
      "for i ←n −1 down to 1 do\n",
      "8\n",
      "u ←prev(ti, u)\n",
      "9\n",
      "if v −u = n −1 then\n",
      "10\n",
      "return [u, v]\n",
      "11\n",
      "else\n",
      "12\n",
      "return nextPhrase(t1t2...tn, u)\n",
      "Figure 2.2\n",
      "Function to locate the ﬁrst occurrence of a phrase after a given position. The function calls\n",
      "the next and prev methods of the inverted index ADT and returns an interval in the text collection\n",
      "as a result.\n",
      "present an algorithm that formalizes this process, eﬃciently locating all occurrences of a given\n",
      "phrase with the aid of our inverted index ADT.\n",
      "We specify the location of a phrase by an interval [u,v], where u indicates the start of the\n",
      "phrase and v indicates the end of the phrase. In addition to the occurrence at [745406, 745407],\n",
      "the phrase “ﬁrst witch” may be found at [745466, 745467], at [745501, 745502], and elsewhere.\n",
      "The goal of our phrase searching algorithm is to determine values of u and v for all occurrences\n",
      "of the phrase in the collection.\n",
      "We use the above interval notation to specify retrieval results throughout the book. In some\n",
      "contexts it is also convenient to think of an interval as a stand-in for the text at that location.\n",
      "For example, the interval [914823, 914829] might represent the text\n",
      "O Romeo, Romeo! wherefore art thou Romeo?\n",
      "Given the phrase “t1t2...tn”, consisting of a sequence of n terms, our algorithm works through\n",
      "the postings lists for the terms from left to right, making a call to the next method for each\n",
      "term, and then from right to left, making a call to the prev method for each term. After each\n",
      "pass from left to right and back, it has computed an interval in which the terms appear in the\n",
      "correct order and as close together as possible. It then checks whether the terms are in fact\n",
      "adjacent. If they are, an occurrence of the phrase has been found; if not, the algorithm moves\n",
      "on.\n",
      "Figure 2.2 presents the core of the algorithm as a function nextPhrase that locates the next\n",
      "occurrence of a phrase after a given position. The loop over lines 2–3 calls the methods of the\n",
      "inverted index to locate the terms in order. At the end of the loop, if the phrase occurs in the\n",
      "interval [position,v], it ends at v. The loop over lines 7–8 then shrinks the interval to the smallest\n",
      "2.1\n",
      "Inverted Indices\n",
      "37\n",
      "size possible while still including all terms in order. Finally, lines 9–12 verify that the terms are\n",
      "adjacent, forming a phrase. If they are not adjacent, the function makes a tail-recursive call.\n",
      "On line 12, note that u (and not v) is passed as the second argument to the recursive call. If\n",
      "the terms in the phrase are all diﬀerent, then v could be passed. Passing u correctly handles\n",
      "the case in which two terms ti and tj are equal (1 ≤i < j ≤n).\n",
      "As an example, suppose we want to ﬁnd the ﬁrst occurrences of the phrase “ﬁrst witch”:\n",
      "nextPhrase(“ﬁrst witch”, −∞). The algorithm starts by identifying the ﬁrst occurrence of\n",
      "“ﬁrst”:\n",
      "next(“ﬁrst”, −∞) = ﬁrst(“ﬁrst”) = 2205.\n",
      "If this occurrence of “ﬁrst” is part of the phrase, then the next occurrence of “witch” should\n",
      "immediately follow it. However,\n",
      "next(“witch”, 2205) = 27555;\n",
      "that is, it does not immediately follow it. We now know that the ﬁrst occurrence of the phrase\n",
      "cannot end before position 27555, and we compute\n",
      "prev(“ﬁrst”, 27555) = 26267.\n",
      "In jumping from 2205 to 26267 in the postings list for “ﬁrst”, we were able to skip 15 occurrences\n",
      "of “ﬁrst”. Because interval [26267, 27555] has length 1288, and not the required length 2, we\n",
      "move on to consider the next occurrence of “ﬁrst” at\n",
      "next(“ﬁrst”, 26267) = 27673.\n",
      "Note that the calls to the prev method in line 8 of the algorithm are not strictly necessary (see\n",
      "Exercise 2.2), but they help us to analyze the complexity of the algorithm.\n",
      "If we want to generate all occurrences of the phrase instead of just a single occurrence, an\n",
      "additional loop is required, calling nextPhrase once for each occurrence of the phrase:\n",
      "u ←−∞\n",
      "while u < ∞do\n",
      "[u,v] ←nextPhrase(“t1t2...tn”, u)\n",
      "if u ̸= ∞then\n",
      "report the interval [u,v]\n",
      "The loop reports each interval as it is generated. Depending on the application, reporting [u,v]\n",
      "might involve returning the document containing the phrase to the user, or it might involve\n",
      "storing the interval in an array or other data structure for further processing. Similar to the\n",
      "code in Figure 2.2, u (and not v) is passed as the second argument to nextPhrase. As a result,\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "38\n",
      "the function can correctly locate all six occurrences of the phrase “spam spam spam” in the\n",
      "follow passage from the well-known Monty Python song:\n",
      "Spam spam spam spam\n",
      "Spam spam spam spam\n",
      "To determine the time complexity of the algorithm, ﬁrst observe that each call to nextPhrase\n",
      "makes O(n) calls to the next and prev methods of the inverted index (n calls to next, followed\n",
      "by n −1 calls to prev). After line 8, the interval [u,v] contains all terms in the phrase in order,\n",
      "and there is no smaller interval contained within it that also contains all the terms in order.\n",
      "Next, observe that each occurrence of a term ti in the collection can be included in no more than\n",
      "one of the intervals computed by lines 1–8. Even if the phrase contains two identical terms, ti\n",
      "and tj, a matching token in the collection can be included in only one such interval as a match\n",
      "to ti, although it might be included in another interval as a match to tj. The time complexity\n",
      "is therefore determined by the length of the shortest postings list for the terms in the phrase:\n",
      "l = min\n",
      "1≤i≤n lti.\n",
      "(2.1)\n",
      "Combining these observations, in the worst case the algorithm requires O(n·l) calls to methods\n",
      "of our ADT to locate all occurrences of the phrase. If the phrase includes both common and\n",
      "uncommon terms (“Rosencrantz and Guildenstern are dead”), the number of calls is determined\n",
      "by the least frequent term (“Guildenstern”) and not the most frequent one (“and”).\n",
      "We emphasize that O(n · l) represents the number of method calls, not the number of steps\n",
      "taken by the algorithm, and that the time for each method call depends on the details of how\n",
      "it is implemented. For the access patterns generated by the algorithm, there is a surprisingly\n",
      "simple and eﬃcient implementation that gives good performance for phrases containing any\n",
      "mixture of frequent and infrequent terms. We present the details in the next section.\n",
      "Although the algorithm requires O(n · l) method calls in the worst case, the actual number\n",
      "of calls depends on the relative location of the terms in the collection. For example, suppose we\n",
      "are searching for the phrase “hello world” and the text in the collection is arranged:\n",
      "hello ... hello ... hello ... hello world ... world ... world ... world\n",
      "with all occurrences of “hello” before all occurrences of “world”. Then the algorithm makes only\n",
      "four method calls to locate the single occurrence of the phrase, regardless of the size of the text\n",
      "or the number of occurrences of each term. Although this example is extreme and artiﬁcial, it\n",
      "illustrates the adaptive nature of the algorithm — its actual execution time is determined by\n",
      "characteristics of the data. Other IR problems may be solved with adaptive algorithms, and we\n",
      "exploit this approach whenever possible to improve eﬃciency.\n",
      "To make the adaptive nature of the algorithm more explicit, we introduce a measure of the\n",
      "characteristics of the data that determines the actual number of method calls. Consider the\n",
      "interval [u,v] just before the test at line 9 of Figure 2.2. The interval contains all the terms in\n",
      "2.1\n",
      "Inverted Indices\n",
      "39\n",
      "the phrase in order, but does not contain any smaller interval containing all the terms in order.\n",
      "We call an interval with this property a candidate phrase for the terms. If we deﬁne κ to be the\n",
      "number of candidate phrases in a given document collection, then the number of method calls\n",
      "required to locate all occurrences is O(n · κ).\n",
      "2.1.2\n",
      "Implementing Inverted Indices\n",
      "It moves across the blackness that lies between stars, and its mechanical legs move slowly.\n",
      "Each step that it takes, however, crossing from nothing to nothing, carries it twice the\n",
      "distance of the previous step. Each stride also takes the same amount of time as the prior\n",
      "one. Suns ﬂash by, fall behind, wink out. It runs through solid matter, passes through\n",
      "infernos, pierces nebulae, faster and faster moving through the starfall blizzard in the\n",
      "forest of the night. Given a suﬃcient warm-up run, it is said that it could circumnavigate\n",
      "the universe in a single stride. What would happen if it kept running after that, no one\n",
      "knows.\n",
      "— Roger Zelazny, Creatures of Light and Darkness\n",
      "When a collection will never change and when it is small enough to be maintained entirely\n",
      "in memory, an inverted index may be implemented with very simple data structures. The\n",
      "dictionary may be stored in a hash table or similar structure, and the postings list for each term\n",
      "t may be stored in a ﬁxed array Pt[] with length lt. For the term “witch” in the Shakespeare\n",
      "collection, this array may be represented as follows:\n",
      "1\n",
      "2\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "92\n",
      "1598\n",
      "27555\n",
      "· · ·\n",
      "745407\n",
      "745429\n",
      "745451\n",
      "745467\n",
      "· · ·\n",
      "1245276\n",
      "The ﬁrst and last methods of our inverted index ADT may be implemented in constant time\n",
      "by returning Pt[1] and Pt[lt], respectively. The next and prev methods may be implemented\n",
      "by a binary search with time complexity O(log(lt)). Details for the next method are provided\n",
      "in Figure 2.3; the details for the prev method are similar.\n",
      "Recall that the phrase searching algorithm of Section 2.1.1 requires O(n · l) calls to the next\n",
      "and prev methods in the worst case. If we deﬁne\n",
      "L = max\n",
      "1≤i≤n lti ,\n",
      "(2.2)\n",
      "then the time complexity of the algorithms becomes O(n · l · log(L)) because each call to a\n",
      "method may require up to O(log(L)) time. When expressed in terms of κ, the number of\n",
      "candidate phrases, the time complexity becomes O(n · κ · log(L)).\n",
      "When a phrase contains both frequent and infrequent terms, this implementation can provide\n",
      "excellent performance. For example, the term “tempest” appears only 49 times in the works of\n",
      "Shakespeare. As we saw in Section 1.3.3, the term “the” appears 28,317 times. However, when\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "40\n",
      "next (t, current) ≡\n",
      "1\n",
      "if lt = 0 or Pt[lt] ≤current then\n",
      "2\n",
      "return ∞\n",
      "3\n",
      "if Pt[1] > current then\n",
      "4\n",
      "return Pt[1]\n",
      "5\n",
      "return Pt[binarySearch (t, 1, lt, current)]\n",
      "binarySearch (t, low, high, current) ≡\n",
      "6\n",
      "while high −low > 1 do\n",
      "7\n",
      "mid ←⌊(low + high)/2⌋\n",
      "8\n",
      "if Pt[mid] ≤current then\n",
      "9\n",
      "low ←mid\n",
      "10\n",
      "else\n",
      "11\n",
      "high ←mid\n",
      "12\n",
      "return high\n",
      "Figure 2.3\n",
      "Implementation of the next method through a binary search that is implemented by a\n",
      "separate function. The array Pt[] (of length lt) contains the postings list for term t. The binarySearch\n",
      "function assumes that Pt[low] ≤current and Pt[high] > current. Lines 1–4 establish this precondition,\n",
      "and the loop at lines 6–11 maintains it as an invariant.\n",
      "searching for the phrase “the tempest”, we access the postings list array for “the” less than two\n",
      "thousand times while conducting at most 2 · 49 = 98 binary searches.\n",
      "On the other hand, when a phrase contains terms with similar frequencies, the repeated\n",
      "binary searches may be wasteful. The terms in the phrase “two gentlemen” both appear a few\n",
      "hundred times in Shakespeare (702 and 225 times, to be exact). Identifying all occurrences of\n",
      "this phrase requires more than two thousand accesses to the postings list array for “two”. In this\n",
      "case, it would be more eﬃcient if we could scan sequentially through both arrays at the same\n",
      "time, comparing values as we go. By changing the deﬁnition of the next and prev methods,\n",
      "the phrase search algorithm can be adapted to do just that.\n",
      "To start with, we note that as the phrase search algorithm makes successive calls to the next\n",
      "method for a given term ti, the values passed as the second argument strictly increase across\n",
      "calls to nextPhrase, including the recursive calls. During the process of ﬁnding all occurrences\n",
      "of a given phrase, the algorithm may make up to l calls to next for that term (where l, as\n",
      "before, is the length of the shortest postings list):\n",
      "next(ti, v1), next(ti, v2), ..., next(ti, vl)\n",
      "with\n",
      "v1 < v2 < ... < vl .\n",
      "Moreover, the results of these calls also strictly increase:\n",
      "next(ti, v1) < next(ti, v2) < ... < next(ti, vl) .\n",
      "2.1\n",
      "Inverted Indices\n",
      "41\n",
      "next (t, current) ≡\n",
      "1\n",
      "if lt = 0 or Pt[lt] ≤current then\n",
      "2\n",
      "return ∞\n",
      "3\n",
      "if Pt[1] > current then\n",
      "4\n",
      "ct ←1\n",
      "5\n",
      "return Pt[ct]\n",
      "6\n",
      "if ct > 1 and Pt[ct −1] > current then\n",
      "7\n",
      "ct ←1\n",
      "8\n",
      "while Pt[ct] ≤current do\n",
      "9\n",
      "ct ←ct + 1\n",
      "10\n",
      "return Pt[ct]\n",
      "Figure 2.4\n",
      "Implementation of the next method through a linear scan. This implementation updates\n",
      "a cached index oﬀset ct for each term t, where Pt[ct] represents the last noninﬁnite result returned from\n",
      "a call to next for this term. If possible, the implementation starts its scan from this cached oﬀset. If\n",
      "not, the cached oﬀset is reset at lines 6–7.\n",
      "For example, when searching for “ﬁrst witch” in Shakespeare, the sequence of calls for “ﬁrst”\n",
      "begins:\n",
      "next(“ﬁrst”, −∞), next(“ﬁrst”, 26267), next(“ﬁrst”, 30608), ...\n",
      "returning the values\n",
      "2205 < 27673 < 32995 < ...\n",
      "Of course, the exact values for v1, v2, . . . and the actual number of calls to next depend on the\n",
      "locations of the other terms in the phrase. Nonetheless, we know that these values will increase\n",
      "and that there may be l of them in the worst case.\n",
      "To implement our sequential scan, we remember (or cache) the value returned by a call to\n",
      "next for a given term. When the function is called again (for the same term), we continue our\n",
      "scan at this cached location. Figure 2.4 provides the details. The variable ct caches the array\n",
      "oﬀset of the value returned by the previous call, with a separate value cached for each term in\n",
      "the phrase (e.g., cﬁrst and cwitch). Because the method may be used in algorithms that do not\n",
      "process postings lists in a strictly increasing order, we are careful to reset ct if this assumption\n",
      "is violated (lines 6–7).\n",
      "If we take a similar approach to implementing prev and maintain corresponding cached\n",
      "values, the phrase search algorithm scans the postings lists for the terms in the phrase, accessing\n",
      "each element of the postings list arrays a bounded number of times (O(1)). Because the algorithm\n",
      "may fully scan the longest postings list (of size L), and all postings lists may be of this length,\n",
      "the overall time complexity of the algorithm is O(n · L). In this case the adaptive nature of the\n",
      "algorithm provides no beneﬁt.\n",
      "We now have two possible implementations for next and prev that in eﬀect produce\n",
      "two implementations of nextPhrase. The ﬁrst implementation, with overall time complex-\n",
      "ity O(n · l · log(L)), is particularly appropriate when the shortest postings list is considerably\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "42\n",
      "next (t, current) ≡\n",
      "1\n",
      "if lt = 0 or Pt[lt] ≤current then\n",
      "2\n",
      "return ∞\n",
      "3\n",
      "if Pt[1] > current then\n",
      "4\n",
      "ct ←1\n",
      "5\n",
      "return Pt[ct]\n",
      "6\n",
      "if ct > 1 and Pt[ct −1] ≤current then\n",
      "7\n",
      "low ←ct −1\n",
      "8\n",
      "else\n",
      "9\n",
      "low ←1\n",
      "10\n",
      "jump ←1\n",
      "11\n",
      "high ←low + jump\n",
      "12\n",
      "while high < lt and Pt[high] ≤current do\n",
      "13\n",
      "low ←high\n",
      "14\n",
      "jump ←2 · jump\n",
      "15\n",
      "high ←low + jump\n",
      "16\n",
      "if high > lt then\n",
      "17\n",
      "high ←lt\n",
      "18\n",
      "ct ←binarySearch (t, low, high, current)\n",
      "19\n",
      "return Pt[ct]\n",
      "Figure 2.5\n",
      "Implementation of the next method through a galloping search. Lines 6–9 determine an\n",
      "initial value for low such that Pt[low] ≤current, using the cached value if possible. Lines 12–17 gallop\n",
      "ahead in exponentially increasing steps until they determine a value for high such that Pt[high] > current.\n",
      "The ﬁnal result is determined by a binary search (from Figure 2.3).\n",
      "shorter than the longest postings list (l ≪L). The second implementation, with time complexity\n",
      "O(n · L), is appropriate when all postings lists have approximately the same length (l ≈L).\n",
      "Given this dichotomy, we might imagine choosing between the algorithms at run-time by\n",
      "comparing l with L. However, it is possible to deﬁne a third implementation of the methods\n",
      "that combines features of both algorithms, with a time complexity that explicitly depends on\n",
      "the relative sizes of the longest and shortest lists (L/l). This third algorithm is based on an\n",
      "exponential or galloping search. The idea is to scan forward from a cached position in exponen-\n",
      "tially increasing steps (“galloping”) until the answer is passed. At this point, a binary search is\n",
      "applied to the range formed by the last two steps of the gallop to locate the exact oﬀset of the\n",
      "answer. Figure 2.5 provides the details.\n",
      "Figure 2.6 illustrates and compares the three approaches for a call to prev(“witch”, 745429)\n",
      "over the Shakespeare collection. Using a binary search (part a), the method would access the\n",
      "array seven times, ﬁrst at positions 1 and 92 to establish the invariant required by the binary\n",
      "search (not shown), and then at positions 46, 23, 34, 28, and 31 during the binary search\n",
      "itself. Using a sequential scan (part b) starting from an initial cached oﬀset of 1, the method\n",
      "would access the array 34 times, including the accesses required to check boundary conditions\n",
      "(not shown). A galloping search (part c) would access positions 1, 2, 4, 8, 16, and 32 before\n",
      "2.1\n",
      "Inverted Indices\n",
      "43\n",
      "\u0002\u0003\u0004\u0003\u0005\u0002\u0006 \u0002\u0003\u0004\u0003\u0006 \u0002\u0003\u0004\u0003\u0004\t\u0006 \u0002\u0003\u0004\u0003\n",
      "\u0002\u0006\n",
      "\t\u0007\u0003\u0004\u0007\u0002\n",
      "\u0006\n",
      "\t\n",
      "\u0007\n",
      "\u000b\t\n",
      "\u000b\u0007\n",
      "\u000b\u000b\n",
      "\u000b\u0003\n",
      "\b\u0007\n",
      "\u0006\t\f\n",
      "\u000e\n",
      "\u0007\u0002\u0004\u0004\u0004\n",
      "\u000f\u000f\u000f\n",
      "\u000f\u000f\u000f\n",
      "\u0003\n",
      "\u0007\u000b\n",
      "\u0007\f\n",
      "\u0002\u0003\u0004\u0003\u0005\u0002\u0006 \u0002\u0003\u0004\u0003\u0006 \u0002\u0003\u0004\u0003\u0004\t\u0006 \u0002\u0003\u0004\u0003\n",
      "\u0002\u0006\n",
      "\t\u0007\u0003\u0004\u0007\u0002\n",
      "\u0006\n",
      "\t\n",
      "\u0007\n",
      "\u000b\t\n",
      "\u000b\u0007\n",
      "\u000b\u000b\n",
      "\u000b\u0003\n",
      "\b\u0007\n",
      "\u0006\t\f\n",
      "\u0002\u000e\n",
      "\u0007\u0002\u0004\u0004\u0004\n",
      "\u000f\u000f\u000f\n",
      "\u000f\u000f\u000f\n",
      "\u000f\u000f\u000f\n",
      "\u0002\u0003\u0004\u0003\u0005\u0002\u0006 \u0002\u0003\u0004\u0003\u0006 \u0002\u0003\u0004\u0003\u0004\t\u0006 \u0002\u0003\u0004\u0003\n",
      "\u0002\u0006\n",
      "\t\u0007\u0003\u0004\u0007\u0002\n",
      "\u0006\n",
      "\t\n",
      "\u0007\n",
      "\u000b\t\n",
      "\u000b\u0007\n",
      "\u000b\u000b\n",
      "\u000b\u0003\n",
      "\b\u0007\n",
      "\u0006\t\f\n",
      "\u0002\u000e\n",
      "\u0007\u0002\u0004\u0004\u0004\n",
      "\u000f\u000f\u000f\n",
      "\u000f\u000f\u000f\n",
      "\f \t\n",
      "\u000f\u000f\u000f\n",
      "\u0003\n",
      "Figure 2.6\n",
      "Access patterns for\n",
      "three\n",
      "approaches to\n",
      "solving\n",
      "prev(“witch”, 745429) = 745407:\n",
      "(a) binary search, (b) sequential scan, and (c) galloping. For (b) and (c), the algorithms start at\n",
      "an initial cached position of 1.\n",
      "establishing the conditions for a binary search, which would then access positions 24, 28, 30,\n",
      "and 31, for a total of twelve accesses to the postings list array (including checking the boundary\n",
      "conditions). At the end of both the scanning and the galloping methods, the cached array oﬀset\n",
      "would be updated to 31.\n",
      "To determine the time complexity of galloping search, we return to consider the sequence of\n",
      "calls to next that originally motivated the sequential scanning algorithm. Let cj\n",
      "t be the cached\n",
      "value after the jth call to next for term t during the processing of a given phrase search.\n",
      "Pt[c1\n",
      "t]\n",
      "=\n",
      "next (t, v1)\n",
      "Pt[c2\n",
      "t]\n",
      "=\n",
      "next (t, v2)\n",
      ". . .\n",
      "Pt[cl\n",
      "t]\n",
      "=\n",
      "next (t, vl)\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "44\n",
      "For a galloping search the amount of work done by a particular call to next depends on the\n",
      "change in the cached value from call to call. If the cached value changes by Δc, then the amount\n",
      "of work done by a call is O(log(Δc)). Thus, if we deﬁne\n",
      "Δc1\n",
      "=\n",
      "c1\n",
      "t\n",
      "Δc2\n",
      "=\n",
      "c2\n",
      "t −c1\n",
      "t\n",
      ". . .\n",
      "Δcl\n",
      "=\n",
      "cl\n",
      "t −cl−1\n",
      "t\n",
      ",\n",
      "then the total work done by calls to next for term t is\n",
      "l\n",
      "\u0002\n",
      "j=1\n",
      "O(log(Δcj)) = O\n",
      "⎛\n",
      "⎝log\n",
      "⎛\n",
      "⎝\n",
      "l\f\n",
      "j=1\n",
      "Δcj\n",
      "⎞\n",
      "⎠\n",
      "⎞\n",
      "⎠.\n",
      "(2.3)\n",
      "We know that the arithmetic mean of a list of nonnegative numbers is always greater than\n",
      "its geometric mean\n",
      "\u0003l\n",
      "j=1 Δcj\n",
      "l\n",
      "≥\n",
      "l\n",
      "\n",
      "\u000e\n",
      "\u000e\n",
      "\u000f\n",
      "l\f\n",
      "j=1\n",
      "Δcj ,\n",
      "(2.4)\n",
      "and since \u0003l\n",
      "j=1 Δcj ≤L, we have\n",
      "l\f\n",
      "j=1\n",
      "Δcj ≤(L/l)l.\n",
      "(2.5)\n",
      "Therefore, the total work done by calls to next (or prev) for the term t is\n",
      "O\n",
      "⎛\n",
      "⎝log\n",
      "⎛\n",
      "⎝\n",
      "l\f\n",
      "j=1\n",
      "Δcj\n",
      "⎞\n",
      "⎠\n",
      "⎞\n",
      "⎠\n",
      "⊆\n",
      "O\n",
      "\n",
      "log\n",
      "\n",
      "(L/l)l\u000b\u000b\n",
      "(2.6)\n",
      "=\n",
      "O (l · log (L/l)) .\n",
      "(2.7)\n",
      "The overall time complexity for a phrase with n terms is O (n · l · log (L/l)). When l ≪L, this\n",
      "performance is similar to that of binary search; when l ≈L, it is similar to scanning. Taking the\n",
      "adaptive nature of the algorithm into account, a similar line of reasoning gives a time complexity\n",
      "of O(n · κ · log(L/κ)).\n",
      "Although we have focused on phrase searching in our discussion of the implementation\n",
      "of inverted indices, we shall see that galloping search is an appropriate technique for other\n",
      "problems, too. Part II of the book extends these ideas to data structures stored on disk.\n",
      "2.1\n",
      "Inverted Indices\n",
      "45\n",
      "2.1.3\n",
      "Documents and Other Elements\n",
      "Most IR systems and algorithms operate over a standard unit of retrieval: the document. As was\n",
      "discussed in Chapter 1, requirements of the speciﬁc application environment determine exactly\n",
      "what constitutes a document. Depending on these requirements, a document might be an e-mail\n",
      "message, a Web page, a newspaper article, or similar element.\n",
      "In many application environments, the deﬁnition of a document is fairly natural. However,\n",
      "in a few environments, such as a collection of books, the natural unit (an entire book) may\n",
      "sometimes be too large to return as a reasonable result, particularly when the relevant material\n",
      "is limited to a small part of the text. Instead, it may be desirable to return a chapter, a section,\n",
      "a subsection, or even a range of pages.\n",
      "In the case of our collection of Shakespeare’s plays, the most natural course is probably to\n",
      "treat each play as a document, but acts, scenes, speeches, and lines might all be appropriate\n",
      "units of retrieval in some circumstances. For the purposes of a simple example, assume we are\n",
      "interested in speeches and wish to locate those spoken by the “ﬁrst witch”.\n",
      "The phrase “ﬁrst witch” ﬁrst occurs at [745406, 745407]. Computing the speech that contains\n",
      "this phrase is reasonably straightforward. Using the methods of our inverted index ADT, we\n",
      "determine that the start of a speech immediately preceding this phrase is located at\n",
      "prev(“<SPEECH>”, 745406) = 745404.\n",
      "The end of this speech is located at\n",
      "next(“</SPEECH>”, 754404) = 745425.\n",
      "Once we conﬁrm that the interval [745406, 745407] is contained in the interval [745404, 745425],\n",
      "we know we have located a speech that contains the phrase. This check to conﬁrm the contain-\n",
      "ment is necessary because the phrase may not always occur as part of a speech. If we wish to\n",
      "locate all speeches by the “ﬁrst witch”, we can repeat this process with the next occurrence of\n",
      "the phrase.\n",
      "A minor problem remains. Although we know that the phrase occurs in the speech, we do\n",
      "not know that the “ﬁrst witch” is the speaker. The phrase may actually appear in the lines\n",
      "spoken. Fortunately, conﬁrming that the witch is the speaker requires only two additional calls\n",
      "to methods of the inverted index (Exercise 2.4). In fact, simple calls to these methods are\n",
      "suﬃcient to compute a broad range of structural relationships, such as the following:\n",
      "1. Lines spoken by any witch.\n",
      "2. The speaker who says, “To be or not to be”.\n",
      "3. Titles of plays mentioning witches and thunder.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "46\n",
      "In a broader context, this ﬂexible approach to specifying retrieval units and ﬁltering them\n",
      "with simple containment criteria has many applications. In Web search systems, simple ﬁltering\n",
      "can restrict retrieval results to a single domain. In enterprise search, applying constraints to\n",
      "the sender ﬁeld allows us to select messages sent by a particular person. In ﬁle system search,\n",
      "structural constraints may be used to determine if ﬁle permissions and security restrictions allow\n",
      "a user to search a directory.\n",
      "Because a requirement for “lightweight” structure occurs frequently in IR applications, we\n",
      "adopt a simple and uniform approach to supporting this structure by incorporating it directly\n",
      "into the inverted index, making it part of the basic facilities an inverted index provides. The\n",
      "examples above illustrate our approach. Complete details will be presented in Chapter 5, in\n",
      "which the approach forms the basis for implementing the advanced search operators, which are\n",
      "widely used in domain-speciﬁc IR applications, such as legal search. The approach may be used\n",
      "to implement the diﬀerential ﬁeld weighting described in Section 8.7, which recognizes that\n",
      "the presence of a query term in a document’s title may be a stronger indicator of relevance\n",
      "than its presence in the body. The approach may also be used to provide a foundation for the\n",
      "implementation of the more complex index structures required to fully support XML retrieval\n",
      "(see Chapter 16).\n",
      "Notwithstanding those circumstances in which lightweight structure is required, most IR\n",
      "research assumes that the text collection naturally divides into documents, which are considered\n",
      "to be atomic units for retrieval. In a system for searching e-mail, messages form this basic\n",
      "retrieval unit. In a ﬁle system, ﬁles do; on the Web, Web pages. In addition to providing a natural\n",
      "unit of retrieval, documents also provide natural divisions in the text, allowing a collection to\n",
      "be partitioned into multiple subcollections for parallel retrieval and allowing documents to be\n",
      "reordered to improve eﬃciency, perhaps by grouping all documents from a single source or Web\n",
      "site.\n",
      "Document-Oriented Indices\n",
      "Because document retrieval represents such an important special case, indices are usually opti-\n",
      "mized around it. To accommodate this optimization, the numbering of positions in a document\n",
      "collection may be split into two components: a document number and an oﬀset within the\n",
      "document.\n",
      "We use the notation n:m to indicate positions within a document-oriented index in which n\n",
      "is a document identiﬁer (or docid) and m is an oﬀset. Figure 2.7 presents an inverted index for\n",
      "Shakespeare’s plays that treats plays as documents. The methods of our inverted index ADT\n",
      "continue to operate as before, but they accept docid:oﬀset pairs as arguments and return them\n",
      "as results.\n",
      "2.1\n",
      "Inverted Indices\n",
      "47\n",
      "\u0002\u0003\u0004\u0005\u0003\u0006\t\n",
      "\f\u000e\u000f\u0003\f\u0005\f\n",
      "\u0002\u0003\u0004\u0005\u0006\u0007\u0007\u0007\n",
      "\b\t\u0004\n",
      "\u000b\f\t\u0004\n",
      "\u000b\u0007\u0007\u0007\n",
      "\u0007\u0007\u0007\n",
      "\u000e\u0004\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u0010\u0004\u0011\u0002\u0006\u0007\u0007\u0007\n",
      "\u000f\u0003\u0006\u000e\u0005\u0007\u0007\u0007\n",
      "\u0012\u0007\u0007\u0007\n",
      "\u0013\u0015\u0016\u0017\u0018\u0019\u0007\u0007\u0007\n",
      "\u0013\u001a\u0015\u001b\u0017\u001c\u001b\u001d\u0019\u0007\u0007\u0007\n",
      "\u0013\u001a\u0015\u001b\u001b\u001e\u001f\u0019\u0007\u0007\u0007\n",
      "\u0013 \u001a\u0015\u001b\u001b\u001e\u001f\u0019\u0007\u0007\u0007\n",
      "\u0013 \u0015\u0016\u0017\u0018\u0019\u0007\u0007\u0007\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "\u0014\u0015\u0016\u0016\u0017\u0018\u0019\u0007\u0014\u0015\u0016\u0016\u001a\u001b\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001a\u0018\u0019\u0007\u0016\u0016\u0015\u001d\u0016\u0018\u0019\u0007\u0016\u0016\u0015\u001d\u001a\u0017\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a\u001b\u001b\u001a\n",
      ",\u0015\u001d\u0017,\u001a\u001d\u0019\u0007\u0016\u0016\u0015\u0016,\u001d\n",
      "\u0014\u0015\u0014\u001e\u0019\u0007\u0014\u0015-,\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001e\u001e\u0019\u0007\u0016\u0016\u0015\u0016\u001b\u0014\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a\u001b\u001e,\n",
      "\u0014\u0015\u001d\u001a\u001b,\u001b\u0019\u0007\u0018\u0015\u001a-\u0017\u0016\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u0018\u001a\u0019\u0007\u0016\u0016\u0015\u0016\u001e\u001b\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u0014\u0016\u0018\u001d\u001b\n",
      "\u0014\u0015\u0014\u0018,\u001b\u0019\u0007\u0014\u0015\u0016\u001e\u0018\u0018\u0018\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001a\u001a\u0019\u0007\u0016\u0016\u0015\u0016\u001b\u001b\u0019\u0007\u0016\u0016\u0015\u001d\u0014\u0017\u0019\u0007\u0016\u0016\u0015\u001d\u0016\u001a\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u0014\u0017\u001a\u001e\u0018\n",
      "\u0014\u0015\u001e\u0014\u001e-\u0019\u0007\u0018\u0015\u001d-\u001d\u0014\u001a\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u0016-\u001b\u0017\u0018\n",
      "-\u0015\u001d\u0017\u001e-\u0019\u0007-\u0015\u0014\u0014\u0016\u001d,\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001a\u0014\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0014\u001e\u001e-\u0016\n",
      "\u001b\u0015\u0016\u0018\u001b\u0017\u0018\n",
      "\u0014\u0015\u0014\u0019\u0007\u0016\u0015\u0014\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u0014\n",
      "\u0014\u0015\u001d\u0014\u001d\u0019\u0007\u0014\u0015-\u001e\u0016\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001a-\u0019\u0007\u0016\u0016\u0015\u0016\u001b\u001a\u0019\u0007\u0016\u0016\u0015\u001d\u0017\u001b\u0019\u0007\u0016\u0016\u0015\u001d\u0016-\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a\u001a\u001e\u001d\n",
      "\u0014\u0015\u001d\u0014\u0016\u0019\u0007\u0014\u0015-\u001e\u0014\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001a\u001d\u0019\u0007\u0016\u0016\u0015\u0016\u001b\u0018\u0019\u0007\u0016\u0016\u0015\u001d\u0017\u001e\u0019\u0007\u0016\u0016\u0015\u001d\u0016\u001d\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a\u001a\u001e\u0016\n",
      "\u0014\u0015-\u0017\u0018\u0017\u001b\u0019\u0007\u0016\u0015\u001d\u0018\u0017\u001e\u0017\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a,\u0017\u001d\n",
      "\u0014\u0015-\u001e\u0017\u0019\u0007\u0014\u0015-\u001b\u001a\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u0016\u0016\u0015\u0016\u001b-\u0019\u0007\u0016\u0016\u0015\u001d\u0017\u001a\u0019\u0007\u0016\u0016\u0015\u001d\u0016\u0016\u0019\u0007\u0016\u0016\u0015\u001d\u001d\u001d\u0019\u0007\u001c\u001c\u001c\u0019\u0007\u001d\u001e\u0015\u001d\u001a\u001b,\u001e\n",
      "\u0002\u0002\u0002\n",
      "\u0002\u0002\u0002\n",
      "Figure 2.7\n",
      "A document-centric index for Shakespeare’s plays equivalent to the one shown in Figure 2.1\n",
      "(page 34). Each posting is of the form docid:within-document-position.\n",
      "For example,\n",
      "ﬁrst(“hurlyburly”) = 9:30963\n",
      "last(“thunder”) = 37:12538\n",
      "ﬁrst(“witching”) = 8:25805\n",
      "last(“witching”) = 8:25805\n",
      "next(“witch”, 22:288) = 22:310\n",
      "prev(“witch”, 22:310) = 22:288\n",
      "next(“hurlyburly”, 9:30963) = 22:293\n",
      "prev(“hurlyburly”, 22:293) = 9:30963\n",
      "next(“witch”, 37:10675) = ∞\n",
      "prev(“witch”, 1:1598) = −∞\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "48\n",
      "Oﬀsets within a document start at 1 and range up to the length of the document. We continue to\n",
      "use −∞and ∞as beginning-of-ﬁle and end-of-ﬁle markers despite the slight notational incon-\n",
      "sistency, with −∞read as −∞:−∞and ∞read as ∞:∞. When term positions are expressed\n",
      "in this form, their values are compared by treating the document number as the primary key:\n",
      "n:m < n′:m′ if and only if (n < n′ or (n = n′ and m < m′)).\n",
      "We refer to an index whose structure has been optimized to support document-oriented retrieval\n",
      "as a schema-dependent inverted index, because the division of the text into retrieval units (its\n",
      "schema) is determined at the time its inverted index is constructed.\n",
      "An index without these optimizations is a schema-independent inverted index. A schema-\n",
      "independent index allows the deﬁnition of a document to be speciﬁed at query time, with a\n",
      "possible cost in execution time in comparison with its schema-dependent equivalent.\n",
      "To support ranking algorithms, a schema-dependent inverted index usually maintains various\n",
      "document-oriented statistics. We adopt the following notation for these statistics:\n",
      "Nt\n",
      "document frequency\n",
      "the number of documents in the collection containing\n",
      "the term t\n",
      "ft,d\n",
      "term frequency\n",
      "the number of times term t appears in document d\n",
      "ld\n",
      "document length\n",
      "measured in tokens\n",
      "lavg\n",
      "average length\n",
      "average document length across the collection\n",
      "N\n",
      "document count\n",
      "total number of documents in the collection\n",
      "Note that \u0003\n",
      "d∈C ld = \u0003\n",
      "t∈V lt = lC, and lavg = lC/N.\n",
      "Over the collection of Shakespeare’s plays, lavg = 34363. If t = “witch” and d = 22 (i.e.,\n",
      "d = Macbeth), then Nt = 18, ft,d = 52, and ld = 26805. In a schema-dependent index, these\n",
      "statistics are usually maintained as an integral part of the index data structures. With a schema-\n",
      "independent index, they have to be computed at query time with the methods of our inverted\n",
      "index ADT (see Exercise 2.5).\n",
      "To help us write algorithms that operate at the document level, we deﬁne additional methods\n",
      "of our inverted index ADT. The ﬁrst two break down positions into separate docids and oﬀsets:\n",
      "docid(position)\n",
      "returns the docid associated with a position\n",
      "oﬀset(position)\n",
      "returns the within-document oﬀset associated with a position\n",
      "When a posting takes the form [u:v], these methods simply return u and v, respectively. They\n",
      "may also be implemented on top of a schema-independent index, albeit slightly less eﬃciently.\n",
      "We also deﬁne document-oriented versions of our basic inverted index methods that will prove\n",
      "useful in later parts of this chapter:\n",
      "2.1\n",
      "Inverted Indices\n",
      "49\n",
      "ﬁrstDoc(t)\n",
      "returns the docid of the ﬁrst document containing the term t\n",
      "lastDoc(t)\n",
      "returns the docid of the last document containing the term t\n",
      "nextDoc(t, current)\n",
      "returns the docid of the ﬁrst document after current that\n",
      "contains the term t\n",
      "prevDoc(t, current)\n",
      "returns the docid of the last document before current that\n",
      "contains the term t\n",
      "In a schema-dependent index, many postings may now share a common preﬁx in their docids.\n",
      "We can separate out these docids to produce postings of the form\n",
      "(d, ft,d, ⟨p0, ..., pft,d⟩)\n",
      "where ⟨p0, ..., pft,d⟩is the list of the oﬀsets of all ft,d occurrences of the term t within document\n",
      "d. Besides eliminating unnecessary repetition, this notation better reﬂects how the postings are\n",
      "actually represented in an implementation of a schema-dependent index. Using this notation,\n",
      "we would write the postings list for the term “witch” as\n",
      "(1, 3, ⟨1598, 27555, 31463⟩), ..., (22, 52, ⟨266, 288, ...⟩), ..., (37, 1, ⟨10675⟩)\n",
      "In specialized circumstances it may not be necessary for positional oﬀsets to be maintained\n",
      "by an inverted index. Basic keyword search is suﬃcient for some applications, and eﬀective\n",
      "ranking can be supported with document-level statistics. For the simplest ranking and ﬁltering\n",
      "techniques, these document-level statistics are not even required.\n",
      "Based on the type of information found in each postings list, we can distinguish four types of\n",
      "inverted indices, the ﬁrst three of which are schema-dependent:\n",
      "• A docid index is the simplest index type. For each term, it contains the document iden-\n",
      "tiﬁers of all documents in which the term appears. Despite its simplicity, this index type\n",
      "is suﬃcient to support ﬁltering with basic Boolean queries (Section 2.2.3) and a simple\n",
      "form of relevance ranking known as coordination level ranking (Exercise 2.7).\n",
      "• In a frequency index, each entry in an inverted list consists of two components: a doc-\n",
      "ument ID and a term frequency value. Each posting in a frequency index is of the\n",
      "form (d, ft,d). Frequency indices are suﬃcient to support many eﬀective ranking methods\n",
      "(Section 2.2.1), but are insuﬃcient for phrase searching and advanced ﬁltering.\n",
      "• A positional index consists of postings of the form (d, ft,d, ⟨p1, ..., pft,d⟩). Positional indices\n",
      "support all search operations supported by a frequency index. In addition, they can be\n",
      "used to realize phrase queries, proximity ranking (Section 2.2.2), and other query types\n",
      "that take the exact position of a query term within a document into account, including\n",
      "all types of structural queries.\n",
      "• A schema-independent index does not include the document-oriented optimizations found\n",
      "in a positional index, but otherwise the two may be used interchangeably.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "50\n",
      "Table 2.1\n",
      "Text fragment from Shakespeare’s Romeo and Juliet, act I, scene 1.\n",
      "Document ID\n",
      "Document Content\n",
      "1\n",
      "Do you quarrel, sir?\n",
      "2\n",
      "Quarrel sir! no, sir!\n",
      "3\n",
      "If you do, sir, I am for you: I serve as good a man as you.\n",
      "4\n",
      "No better.\n",
      "5\n",
      "Well, sir.\n",
      "Table 2.2\n",
      "Postings lists for the terms shown in Table 2.1. In each case the length of the list is\n",
      "appended to the start of the actual list.\n",
      "Term\n",
      "Docid List\n",
      "Positional List\n",
      "Schema-Independent\n",
      "a\n",
      "1; 3\n",
      "1; (3, 1, ⟨13⟩)\n",
      "1; 21\n",
      "am\n",
      "1; 3\n",
      "1; (3, 1, ⟨6⟩)\n",
      "1; 14\n",
      "as\n",
      "1; 3\n",
      "1; (3, 2, ⟨11, 15⟩)\n",
      "2; 19, 23\n",
      "better\n",
      "1; 4\n",
      "1; (4, 1, ⟨2⟩)\n",
      "1; 26\n",
      "do\n",
      "2; 1, 3\n",
      "2; (1, 1, ⟨1⟩), (3, 1, ⟨3⟩)\n",
      "2; 1, 11\n",
      "for\n",
      "1; 3\n",
      "1; (3, 1, ⟨7⟩)\n",
      "1; 15\n",
      "good\n",
      "1; 3\n",
      "1; (3, 1, ⟨12⟩)\n",
      "1; 20\n",
      "i\n",
      "1; 3\n",
      "1; (3, 2, ⟨5, 9⟩)\n",
      "2; 13, 17\n",
      "if\n",
      "1; 3\n",
      "1; (3, 1, ⟨1⟩)\n",
      "1; 9\n",
      "man\n",
      "1; 3\n",
      "1; (3, 1, ⟨14⟩)\n",
      "1; 22\n",
      "no\n",
      "2; 2, 4\n",
      "2; (2, 1, ⟨3⟩), (4, 1, ⟨1⟩)\n",
      "2; 7, 25\n",
      "quarrel\n",
      "2; 1, 2\n",
      "2; (1, 1, ⟨3⟩), (2, 1, ⟨1⟩)\n",
      "2; 3, 5\n",
      "serve\n",
      "1; 3\n",
      "1; (3, 1, ⟨10⟩)\n",
      "1; 18\n",
      "sir\n",
      "4; 1, 2, 3, 5\n",
      "4; (1, 1, ⟨4⟩), (2, 2, ⟨2, 4⟩), (3, 1, ⟨4⟩), (5, 1, ⟨2⟩)\n",
      "5; 4, 6, 8, 12, 28\n",
      "well\n",
      "1; 5\n",
      "1; (5, 1, ⟨1⟩)\n",
      "1; 27\n",
      "you\n",
      "2; 1, 3\n",
      "2; (1, 1, ⟨2⟩), (3, 3, ⟨2, 8, 16⟩)\n",
      "4; 2, 10, 16, 24\n",
      "Table 2.1 shows an excerpt from Shakespeare’s Romeo and Juliet. Here, each line is treated as\n",
      "a document — we have omitted the tags to help shorten the example to a reasonable length.\n",
      "Table 2.2 shows the corresponding postings lists for all terms that appear in the excerpt, giving\n",
      "examples of docid lists, positional postings lists, and schema-independent postings lists.\n",
      "Of the four diﬀerent index types, the docid index is always the smallest one because it contains\n",
      "the least information. The positional and the schema-independent indices consume the greatest\n",
      "space, between two times and ﬁve times as much space as a frequency index, and between\n",
      "three times and seven times as much as a docid index, for typical text collections. The exact\n",
      "ratio depends on the lengths of the documents in the collection, the skewedness of the term\n",
      "distribution, and the impact of compression. Index sizes for the four diﬀerent index types and\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "51\n",
      "Table 2.3\n",
      "Index sizes for various index types and three test collections, with and without apply-\n",
      "ing index compression techniques. In each case the ﬁrst number refers to an index in which each\n",
      "component is stored as a simple 32-bit integer, and the second number refers to an index in which\n",
      "each entry is compressed using a byte-aligned encoding method.\n",
      "Shakespeare\n",
      "TREC\n",
      "GOV2\n",
      "Docid index\n",
      "n/a\n",
      "578 MB/200 MB\n",
      "37751 MB/12412 MB\n",
      "Frequency index\n",
      "n/a\n",
      "1110 MB/333 MB\n",
      "73593 MB/21406 MB\n",
      "Positional index\n",
      "n/a\n",
      "2255 MB/739 MB\n",
      "245538 MB/78819 MB\n",
      "Schema-independent index\n",
      "5.7 MB/2.7 MB\n",
      "1190 MB/533 MB\n",
      "173854 MB/65960 MB\n",
      "our three example collections are shown in Table 2.3. Index compression has a substantial eﬀect\n",
      "on index size, and it is discussed in detail in Chapter 6.\n",
      "With the introduction of document-oriented indices, we have greatly expanded the notation\n",
      "associated with inverted indices from the four basic methods introduced at the beginning of\n",
      "the chapter. Table 2.4 provides a summary of this notation for easy reference throughout the\n",
      "remainder of the book.\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "Building on the data structures of the previous section, this section presents three simple\n",
      "retrieval methods. The ﬁrst two methods produce ranked results, ordering the documents in\n",
      "the collection according to their expected relevance to the query. Our third retrieval method\n",
      "allows Boolean ﬁlters to be applied to the collection, identifying those documents that match a\n",
      "predicate.\n",
      "Queries for ranked retrieval are often expressed as term vectors. When you type a query into\n",
      "an IR system, you express the components of this vector by entering the terms with white space\n",
      "between them. For example, the query\n",
      "william shakespeare marriage\n",
      "might be entered into a commercial Web search engine with the intention of retrieving a ranked\n",
      "list of Web pages concerning Shakespeare’s marriage to Anne Hathaway. To make the nature\n",
      "of these queries more obvious, we write term vectors explicitly using the notation ⟨t1, t2, ..., tn⟩.\n",
      "The query above would then be written\n",
      "⟨“william”, “shakespeare”, “marriage”⟩.\n",
      "You may wonder why we represent these queries as vectors rather than sets. Representation\n",
      "as a vector (or, rather, a list, since we do not assume a ﬁxed-dimensional vector space) is useful\n",
      "when terms are repeated in a query and when the ordering of terms is signiﬁcant. In ranking\n",
      "formulae, we use the notation qt to indicate the number of times term t appears in the query.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "52\n",
      "Table 2.4\n",
      "Summary of notation for inverted indices.\n",
      "Basic inverted index methods\n",
      "ﬁrst(term)\n",
      "returns the ﬁrst position at which the term occurs\n",
      "last(term)\n",
      "returns the last position at which the term occurs\n",
      "next(term, current)\n",
      "returns the next position at which the term occurs after\n",
      "the current position\n",
      "prev(term, current)\n",
      "returns the previous position at which the term occurs before\n",
      "the current position\n",
      "Document-oriented equivalents of the basic methods\n",
      "ﬁrstDoc(term), lastDoc(term), nextDoc(term, current), lastDoc(term, current)\n",
      "Schema-dependent index positions\n",
      "n:m\n",
      "n = docid and m = oﬀset\n",
      "docid(position)\n",
      "returns the docid associated with a position\n",
      "oﬀset(position)\n",
      "returns the within-document oﬀset associated with a position\n",
      "Symbols for document and term statistics\n",
      "lt\n",
      "the length of t’s postings list\n",
      "Nt\n",
      "the number of documents containing t\n",
      "ft,d\n",
      "the number of occurrences of t within the document d\n",
      "ld\n",
      "length of the document d, in tokens\n",
      "lavg\n",
      "the average document length in the collection\n",
      "N\n",
      "the total number of documents in the collection\n",
      "The structure of postings lists\n",
      "docid index\n",
      "d1, d2, . . . , dNt\n",
      "frequency index\n",
      "(d1, ft,d1), (d2, ft,d2), . . .\n",
      "positional index\n",
      "(d1, ft,d1, ⟨p1, . . . , pft,d1 ⟩), . . .\n",
      "schema-independent\n",
      "p1, p2, . . . , plt\n",
      "Boolean predicates are composed with the standard Boolean operators (AND, OR, NOT).\n",
      "The result of a Boolean query is a set of documents matching the predicate. For example, the\n",
      "Boolean query\n",
      "“william” AND “shakespeare” AND NOT (“marlowe” OR “bacon”)\n",
      "speciﬁes those documents containing the terms “william” and “shakespeare” but not containing\n",
      "either “marlowe” or “bacon”. In later chapters we will extend this standard set of Boolean\n",
      "operators, which will allow us to specify additional constraints on the result set.\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "53\n",
      "There is a key diﬀerence in the conventional interpretations of term vectors for ranked retrieval\n",
      "and predicates for Boolean retrieval. Boolean predicates are usually interpreted as strict ﬁlters —\n",
      "if a document does not match the predicate, it is not returned in the result set. Term vectors, on\n",
      "the other hand, are often interpreted as summarizing an information need. Not all the terms in\n",
      "the vector need to appear in a document for it to be returned. For example, if we are interested\n",
      "in the life and works of Shakespeare, we might attempt to create an exhaustive (and exhausting)\n",
      "query to describe our information need by listing as many related terms as we can:\n",
      "william shakespeare stratford avon london plays sonnets poems tragedy comedy poet\n",
      "playwright players actor anne hathaway susanna hamnet judith folio othello hamlet\n",
      "macbeth king lear tempest romeo juliet julius caesar twelfth night antony cleopatra\n",
      "venus adonis willie hughe wriothesley henry ...\n",
      "Although many relevant Web pages will contain some of these terms, few will contain all of\n",
      "them. It is the role of a ranked retrieval method to determine the impact that any missing\n",
      "terms will have on the ﬁnal document ordering.\n",
      "Boolean retrieval combines naturally with ranked retrieval into a two-step retrieval process.\n",
      "A Boolean predicate is ﬁrst applied to restrict retrieval to a subset of the document collection.\n",
      "The documents contained in the resulting subcollection are then ranked with respect to a given\n",
      "topic. Commercial Web search engines follow this two-step retrieval process. Until recently,\n",
      "most of these systems would interpret the query\n",
      "william shakespeare marriage\n",
      "as both a Boolean conjunction of the terms — “william” AND “shakespeare” AND “marriage” —\n",
      "and as a term vector for ranking — ⟨“william”, “shakespeare”, “marriage”⟩. For a page to be\n",
      "returned as a result, each of the terms was required to appear in the page itself or in the anchor\n",
      "text linking to the page.\n",
      "Filtering out relevant pages that are missing one or more terms may have the paradoxical eﬀect\n",
      "of harming performance when extra terms are added to a query. In principle, adding extra terms\n",
      "should improve performance by serving to better deﬁne the information need. Although some\n",
      "commercial Web search engines now apply less restrictive ﬁlters, allowing additional documents\n",
      "to appear in the ranked results, this two-step retrieval process still takes place. These systems\n",
      "may handle longer queries poorly, returning few or no results in some cases.\n",
      "In determining an appropriate document ranking, basic ranked retrieval methods com-\n",
      "pare simple features of the documents. One of the most important of these features is\n",
      "term frequency, ft,d, the number of times query term t appears in document d. Given two\n",
      "documents d1 and d2, if a query term appears many more times in d1 than in d2, this\n",
      "may suggest that d1 should be ranked higher than d2, other factors being equal. For the\n",
      "query ⟨“william”, “shakespeare”, “marriage”⟩, the repeated occurrence of the term “marriage”\n",
      "throughout a document may suggest that it should be ranked above one containing the term\n",
      "only once.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "54\n",
      "Another important feature is term proximity. If query terms appear closer together in doc-\n",
      "ument d1 than in document d2, this may suggest that d1 should be ranked higher than d2,\n",
      "other factors being equal. In some cases, terms form a phrase (“william shakespeare”) or other\n",
      "collocation, but the importance of proximity is not merely a matter of phrase matching. The\n",
      "co-occurrence of “william”, “shakespeare”, and “marriage” together in a fragment such as\n",
      "... while no direct evidence of the marriage of Anne Hathaway and William Shake-\n",
      "speare exists, the wedding is believed to have taken place in November of 1582, while\n",
      "she was pregnant with his child ...\n",
      "suggests a relationship between the terms that might not exist if they appeared farther apart.\n",
      "Other features help us make trade-oﬀs between competing factors. For example, should a\n",
      "thousand-word document containing four occurrences of “william”, ﬁve of “shakespeare”, and\n",
      "two of “marriage” be ranked before or after a ﬁve-hundred-word document containing three\n",
      "occurrences of “william”, two of “shakespeare”, and seven of “marriage”? These features include\n",
      "the lengths of the documents (ld) relative to the average document length (lavg), as well as the\n",
      "number of documents in which a term appears (Nt) relative to the total number of documents\n",
      "in the collection (N).\n",
      "Although the basic features listed above form the core of many retrieval models and ranking\n",
      "methods, including those discussed in this chapter, additional features may contribute as well.\n",
      "In some application areas, such as Web search, the exploitation of these additional features is\n",
      "critical to the success of a search engine.\n",
      "One important feature is document structure. For example, a query term may be treated\n",
      "diﬀerently if it appears in the title of a document rather than in its body. Often the relationship\n",
      "between documents is important, such as the links between Web documents. In the context\n",
      "of Web search, the analysis of the links between Web pages may allow us to assign them a\n",
      "query-independent ordering or static rank, which can then be a factor in retrieval. Finally, when\n",
      "a large group of people make regular use of an IR system within an enterprise or on the Web,\n",
      "their behavior can be monitored to improve performance. For example, if results from one Web\n",
      "site are clicked more than results from another, this behavior may indicate a user preference for\n",
      "one site over the other — other factors being equal — that can be exploited to improve ranking.\n",
      "In later chapters these and other additional features will be covered in detail.\n",
      "2.2.1\n",
      "The Vector Space Model\n",
      "The vector space model is one of the oldest and best known of the information retrieval models\n",
      "we examine in this book. Starting in the 1960s and continuing into 1990s, the method was\n",
      "developed and promulgated by Gerald Salton, who was perhaps the most inﬂuential of the early\n",
      "IR researchers. As a result, the vector space model is intimately associated with the ﬁeld as a\n",
      "whole and has been adapted to many IR problems beyond ranked retrieval, including document\n",
      "clustering and classiﬁcation, in which it continues to play an important role. In recent years, the\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "55\n",
      "\u0002\n",
      "\u0003\n",
      "\u0002\u0002\n",
      "\u0002\u0003\n",
      "\u0004\u0005\n",
      "\u0004\u0006\n",
      "\u0007\n",
      "Figure 2.8\n",
      "Document similarity under the vector space model. Angles are computed between a query\n",
      "vector ⃗q and two document vectors ⃗d1 and ⃗d2. Because θ1 < θ2, d1 should be ranked higher than d2.\n",
      "vector space model has been largely overshadowed by probabilistic models, language models,\n",
      "and machine learning approaches (see Part III). Nonetheless, the simple intuition underlying it,\n",
      "as well as its long history, makes the vector space model an ideal vehicle for introducing ranked\n",
      "retrieval.\n",
      "The basic idea is simple. Queries as well as documents are represented as vectors in a high-\n",
      "dimensional space in which each vector component corresponds to a term in the vocabulary of the\n",
      "collection. This query vector representation stands in contrast to the term vector representation\n",
      "of the previous section, which included only the terms appearing in the query. Given a query\n",
      "vector and a set of document vectors, one for each document in the collection, we rank the\n",
      "documents by computing a similarity measure between the query vector and each document\n",
      "vector, comparing the angle between them. The smaller the angle, the more similar the vectors.\n",
      "Figure 2.8 illustrates the basic idea, using vectors with only two components (A and B).\n",
      "Linear algebra provides us with a handy formula to determine the angle θ between two vectors.\n",
      "Given two |V|-dimensional vectors ⃗x = ⟨x1, x2, ..., x|V|⟩and ⃗y = ⟨y1, y2, ..., y|V|⟩, we have\n",
      "⃗x · ⃗y = |⃗x| · |⃗y| · cos(θ).\n",
      "(2.8)\n",
      "where ⃗x · ⃗y represents the dot product (also called the inner product or scalar product) between\n",
      "the vectors; |⃗x| and |⃗y| represent the lengths of the vectors. The dot product is deﬁned as\n",
      "⃗x · ⃗y =\n",
      "|V|\n",
      "\u0002\n",
      "i=1\n",
      "xi · yi\n",
      "(2.9)\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "56\n",
      "and the length of a vector may be computed from the Euclidean distance formula\n",
      "|⃗x| =\n",
      "\n",
      "\u000e\n",
      "\u000e\n",
      "\u000f\n",
      "|V|\n",
      "\u0002\n",
      "i=1\n",
      "xi2 .\n",
      "(2.10)\n",
      "Substituting and rearranging these equations gives\n",
      "cos(θ) =\n",
      "⃗x\n",
      "|⃗x| · ⃗y\n",
      "|⃗y| =\n",
      "\u0003|V|\n",
      "i=1 xi yi\n",
      "\u0010\u0011\u0003|V|\n",
      "i=1 xi2\n",
      "\u0012 \u0010\u0011\u0003|V|\n",
      "i=1 yi2\n",
      "\u0012 .\n",
      "(2.11)\n",
      "We could now apply arccos to determine θ, but because the cosine is monotonically decreasing\n",
      "with respect to the angle θ, it is convenient to stop at this point and retain the cosine itself\n",
      "as our measure of similarity. If θ = 0◦, then the vectors are colinear, as similar as possible,\n",
      "with cos(θ) = 1. If θ = 90◦, then the vectors are orthogonal, as dissimilar as possible, with\n",
      "cos(θ) = 0.\n",
      "To summarize, given a document vector ⃗d and a query vector ⃗q, the cosine similarity sim(⃗d, ⃗q)\n",
      "is computed as\n",
      "sim(⃗d, ⃗q) =\n",
      "⃗d\n",
      "|⃗d|\n",
      "· ⃗q\n",
      "|⃗q| ,\n",
      "(2.12)\n",
      "the dot product of the document and query vectors normalized to unit length. Provided all\n",
      "components of the vectors are nonnegative, the value of this cosine similarity measure ranges\n",
      "from 0 to 1, with its value increasing with increasing similarity.\n",
      "Naturally, for a collection of even modest size, this vector space model produces vectors with\n",
      "millions of dimensions. This high-dimensionality might appear ineﬃcient at ﬁrst glance, but\n",
      "in many circumstances the query vector is sparse, with all but a few components being zero.\n",
      "For example, the vector corresponding to the query ⟨“william”, “shakespeare”, “marriage”⟩has\n",
      "only three nonzero components. To compute the length of this vector, or its dot product with\n",
      "a document vector, we need only consider the components corresponding to these three terms.\n",
      "On the other hand, a document vector typically has a nonzero component for each unique\n",
      "term contained in the document, which may consist of thousands of terms. However, the length\n",
      "of a document vector is independent of the query. It may be precomputed and stored in a\n",
      "frequency or positional index along with other document-speciﬁc information, or it may be\n",
      "applied to normalize the document vector in advance, with the components of the normalized\n",
      "vector taking the place of term frequencies in the postings lists.\n",
      "Although queries are usually short, the symmetry between how documents and queries are\n",
      "treated in the vector space model allows entire documents to be used as queries. Equation 2.12\n",
      "may then be viewed as a formula determining the similarity between two documents. Treat-\n",
      "ing a document as a query is one possible method for implementing the “Similar pages” and\n",
      "“More like this” features seen in some commercial search engines.\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "57\n",
      "As a ranking method the cosine similarity measure has intuitive appeal and natural simplicity.\n",
      "If we can appropriately represent queries and documents as vectors, cosine similarity may be\n",
      "used to rank the documents with respect to the queries. In representing a document or query as\n",
      "a vector, a weight must be assigned to each term that represents the value of the corresponding\n",
      "component of the vector. Throughout the long history of the vector space model, many formulae\n",
      "for assigning these weights have been proposed and evaluated. With few exceptions, these\n",
      "formulae may be characterized as belonging to a general family known as TF-IDF weights.\n",
      "When assigning a weight in a document vector, the TF-IDF weights are computed by taking\n",
      "the product of a function of term frequency (ft,d) and a function of the inverse of document\n",
      "frequency (1/Nt). When assigning a weight to a query vector, the within-query term frequency\n",
      "(qt) may be substituted for ft,d, in essence treating the query as a tiny document. It is also\n",
      "possible (and not at all unusual) to use diﬀerent TF and IDF functions to determine weights\n",
      "for document vectors and query vectors.\n",
      "\u0002\u0003\u0004\u0005\u0006\u0003\n",
      "\u0002\u0002\u0003\u0004\u0005\u0007\u0002\u0003\u0004\u0005\u0006\u0007\u0004\t\u0003\n",
      "\u000b\f\n",
      "\b\u0002\u0003\u0004\u0005\u0007\n",
      "\u000e\u0003\u0004\u000f\u0003\u0006\u0010\u0011\u000b\t\u0005\u0003\n",
      "\u0002\u0006\u0007\u0004\t\u0003\n",
      "\u000b\f\n",
      "We emphasize that a TF-IDF weight is a product of functions of term frequency and inverse doc-\n",
      "ument frequency. A common error is to use the raw ft,d value for the term frequency component,\n",
      "which may lead to poor performance.\n",
      "Over the years a number of variants for both the TF and the IDF functions have been proposed\n",
      "and evaluated. The IDF functions typically relate the document frequency to the total number\n",
      "of documents in the collection (N). The basic intuition behind the IDF functions is that a term\n",
      "appearing in many documents should be assigned a lower weight than a term appearing in few\n",
      "documents. Of the two functions, IDF comes closer to having a “standard form”,\n",
      "IDF = log(N/Nt),\n",
      "(2.13)\n",
      "with most IDF variants structured as a logarithm of a fraction involving Nt and N.\n",
      "The basic intuition behind the various TF functions is that a term appearing many times in a\n",
      "document should be assigned a higher weight for that document than for a document in which\n",
      "it appears fewer times. Another important consideration behind the deﬁnition of a TF function\n",
      "is that its value should not necessarily increase linearly with ft,d. Although two occurrences of a\n",
      "term should be given more weight than one occurrence, they shouldn’t necessarily be given twice\n",
      "the weight. The following function meets these requirements and appears in much of Salton’s\n",
      "later work:\n",
      "TF =\n",
      "\u0013\n",
      "log(ft,d) + 1\n",
      "if ft,d > 0,\n",
      "0\n",
      "otherwise.\n",
      "(2.14)\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "58\n",
      "When this equation is used with a query vector, ft,d is replaced by qt the query term frequency\n",
      "of t in q. We use this equation, along with Equation 2.13, to compute both document and query\n",
      "weights in the example that follows.\n",
      "Consider the Romeo and Juliet document collection in Table 2.1 (page 50) and the corre-\n",
      "sponding postings lists given in Table 2.2. Because there are ﬁve documents in the collection\n",
      "and “sir” appears in four of them, the IDF value for “sir” is\n",
      "log(N/fsir) = log(5/4) ≈0.32.\n",
      "In this formula and in other TF-IDF formulae involving logarithms, the base of the logarithm\n",
      "is usually unimportant. As necessary, for purposes of this example and others throughout the\n",
      "book, we assume a base of 2.\n",
      "Because “sir” appears twice in document 2, the TF-IDF value for the corresponding\n",
      "component of its vector is\n",
      "(log(fsir,2) + 1) · (log(N/fsir)) = (log(2) + 1) · (log(5/4)) ≈0.64.\n",
      "Computing TF-IDF values for the remaining components and the remaining documents, gives\n",
      "the following set of vectors:\n",
      "⃗d1\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 1.32, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.32, 0.00, 0.32, 0.00, 1.32⟩\n",
      "⃗d2\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.32, 1.32, 0.00, 0.64, 0.00, 0.00⟩\n",
      "⃗d3\n",
      "≈\n",
      "⟨2.32, 2.32, 4.64, 0.00, 1.32, 2.32, 2.32, 4.64, 2.32, 2.32, 0.00, 0.00, 2.32, 0.32, 0.00, 3.42⟩\n",
      "⃗d4\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 2.32, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.32, 0.00, 0.00, 0.00, 0.00, 0.00⟩\n",
      "⃗d5\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.32, 2.32, 0.00⟩\n",
      "where the components are sorted alphabetically according to their corresponding terms.\n",
      "Normalizing these vectors, dividing by their lengths, produces:\n",
      "⃗d1/|⃗d1|\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.57, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.57, 0.00, 0.14, 0.00, 0.57⟩\n",
      "⃗d2/|⃗d2|\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.67, 0.67, 0.00, 0.33, 0.00, 0.00⟩\n",
      "⃗d3/|⃗d3|\n",
      "≈\n",
      "⟨0.24, 0.24, 0.48, 0.00, 0.14, 0.24, 0.24, 0.48, 0.24, 0.24, 0.00, 0.00, 0.24, 0.03, 0.00, 0.35⟩\n",
      "⃗d4/|⃗d4|\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.87, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.49, 0.00, 0.00, 0.00, 0.00, 0.00⟩\n",
      "⃗d5/|⃗d5|\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.14, 0.99, 0.00⟩\n",
      "If we wish to rank these ﬁve documents with respect to the query ⟨“quarrel”, “sir”⟩, we ﬁrst\n",
      "construct the query vector, normalized by length:\n",
      "⃗q/|⃗q|\n",
      "≈\n",
      "⟨0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.97, 0.00, 0.24, 0.00, 0.00⟩\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "59\n",
      "rankCosine (⟨t1, ..., tn⟩, k) ≡\n",
      "1\n",
      "j ←1\n",
      "2\n",
      "d ←min1≤i≤n nextDoc (ti, −∞)\n",
      "3\n",
      "while d < ∞do\n",
      "4\n",
      "Result[j].docid ←d\n",
      "5\n",
      "Result[j].score ←\n",
      "⃗d\n",
      "|⃗d| ·\n",
      "⃗q\n",
      "|⃗q|\n",
      "6\n",
      "j ←j + 1\n",
      "7\n",
      "d ←min1≤i≤n nextDoc (ti, d)\n",
      "8\n",
      "sort Result by score\n",
      "9\n",
      "return Result[1..k]\n",
      "Figure 2.9\n",
      "Query processing for ranked retrieval under the vector space model. Given the term vector\n",
      "⟨t1, ..., tn⟩(with corresponding query vector ⃗q), the function identiﬁes the top k documents.\n",
      "Computing the dot product between this vector and each document vector gives the following\n",
      "cosine similarity values:\n",
      "Document ID\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Similarity\n",
      "0.59\n",
      "0.73\n",
      "0.01\n",
      "0.00\n",
      "0.03\n",
      "The ﬁnal document ranking is 2, 1, 5, 3, 4.\n",
      "Query processing for the vector space model is straightforward (Figure 2.9), essentially per-\n",
      "forming a merge of the postings lists for the query terms. Docids and corresponding scores\n",
      "are accumulated in an array of records as the scores are computed. The function operates on\n",
      "one document at a time. During each iteration of the while loop, the algorithm computes the\n",
      "score for document d (with corresponding document vector ⃗d), stores the docid and score in the\n",
      "array of records Result, and determines the next docid for processing. The algorithm does not\n",
      "explicitly compute a score for documents that do not contain any of the query terms, which are\n",
      "implicitly assigned a score of zero. At the end of the function, Result is sorted by score and the\n",
      "top k documents are returned.\n",
      "For many retrieval applications, the entire ranked list of documents is not required. Instead we\n",
      "return at most k documents, where the value of k is determined by the needs of the application\n",
      "environment. For example, a Web search engine might return only the ﬁrst k = 10 or 20\n",
      "results on its ﬁrst page. It then may seem ineﬃcient to compute the score for every document\n",
      "containing any of the terms, even a single term with low weight, when only the top k documents\n",
      "are required. This apparent ineﬃciency has led to proposals for improved query processing\n",
      "methods that are applicable to other IR models as well as to the vector space model. These\n",
      "query processing methods will be discussed in Chapter 5.\n",
      "Of the document features listed at the start of this section — term frequency, term proximity,\n",
      "document frequency, and document length — the vector space model makes explicit use of\n",
      "only term frequency and document frequency. Document length is handled implicitly when the\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "60\n",
      "vectors are normalized to unit length. If one document is twice as long as another but contains\n",
      "the same terms in the same proportions, their normalized vectors are identical. Term proximity\n",
      "is not considered by the model at all. This property has led to the colorful description of the\n",
      "vector space model (and other IR models with the same property) as a “bag of words” model.\n",
      "We based the version of the vector space model presented in this section on the introductory\n",
      "descriptions given in Salton’s later works. In practice, implementations of the vector space\n",
      "model often eliminate both length normalization and the IDF factor in document vectors, in\n",
      "part to improve eﬃciency. Moreover, the Euclidean length normalization inherent in the cosine\n",
      "similarity measure has proved inadequate to handle collections containing mixtures of long and\n",
      "short documents, and substantial adjustments are required to support these collections. These\n",
      "eﬃciency and eﬀectiveness issues are examined in Section 2.3.\n",
      "The vector space model may be criticized for its entirely heuristic nature. Beyond intuition, its\n",
      "simple mathematics, and the experiments of Section 2.3, we do not provide further justiﬁcation\n",
      "for it. IR models introduced in later chapters (Chapters 8 and 9) are more solidly grounded in\n",
      "theoretical frameworks. Perhaps as a result, these models are more adaptable, and are more\n",
      "readily extended to accommodate additional document features.\n",
      "2.2.2\n",
      "Proximity Ranking\n",
      "The vector space ranking method from the previous section explicitly depends only on TF and\n",
      "IDF. In contrast, the method detailed in this section explicitly depends only on term proximity.\n",
      "Term frequency is handled implicitly; document frequency, document length, and other features\n",
      "play no role at all.\n",
      "When the components of a term vector ⟨t1, t2, . . . , tn⟩appear in close proximity within a\n",
      "document, it suggests that the document is more likely to be relevant than one in which the\n",
      "terms appear farther apart. Given a term vector ⟨t1, t2, ..., tn⟩, we deﬁne a cover for the vector\n",
      "as an interval in the collection [u, v] that contains a match to all the terms without containing\n",
      "a smaller interval [u′, v′], u ≤u′ ≤v′ ≤v, that also contains a match to all the terms. The\n",
      "candidate phrases deﬁned on page 39 are a special case of a cover in which all the terms appear\n",
      "in order.\n",
      "In the collection of Table 2.1 (page 50), the intervals [1:2, 1:4], [3:2, 3:4], and [3:4, 3:8] are\n",
      "covers for the term vector ⟨“you”, “sir”⟩. The interval [3:4, 3:16] is not a cover, even though\n",
      "both terms are contained within it, because it contains the cover [3:4, 3:8]. Similarly, there are\n",
      "two covers for the term vector ⟨“quarrel”, “sir”⟩: [1:3, 1:4] and [2:1, 2:2].\n",
      "Note that covers may overlap. However, a token matching a term ti appears in at most n · l\n",
      "covers, where l is the length of the shortest postings list for the terms in the vector. To see that\n",
      "there may be as many as n · l covers for the term vector ⟨t1, t2, ..., tn⟩, consider a collection in\n",
      "which all the terms occur in the same order the same number of times:\n",
      "... t1 ... t2 ... t3 ... tn ... t1 ... t2 ... t3 ... tn ... t1 ...\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "61\n",
      "nextCover (⟨t1, ..., tn⟩, position) ≡\n",
      "1\n",
      "v ←max1≤i≤n(next(ti, position))\n",
      "2\n",
      "if v = ∞then\n",
      "3\n",
      "return [∞, ∞]\n",
      "4\n",
      "u ←min1≤i≤n(prev(ti, v + 1))\n",
      "5\n",
      "if docid(u) = docid(v) then\n",
      "6\n",
      "return [u, v]\n",
      "7\n",
      "else\n",
      "8\n",
      "return nextCover(⟨t1, ..., tn⟩, u)\n",
      "Figure 2.10\n",
      "Function to locate the next occurrence of a cover for the term vector ⟨t1, ..., tn⟩after a\n",
      "given position.\n",
      "We leave the demonstration that there may be no more than n · l covers to Exercise 2.8. A new\n",
      "cover starts at each occurrence of a term from the vector. Thus, the total number of covers for\n",
      "a term vector is constrained by n · l and does not depend on the length of the longest postings\n",
      "list L. With respect to proximity ranking, we deﬁne κ to be the number of covers for a term\n",
      "vector occurring in a document collection where κ ≤n · l.\n",
      "Perhaps not surprisingly, our algorithm to compute covers is a close cousin of the phrase\n",
      "searching algorithm in Figure 2.2 (page 36). The function in Figure 2.10 locates the next occur-\n",
      "rence of a cover after a given position. On line 1, the algorithm determines the smallest position\n",
      "v such that the interval [position, v] contains all the terms in the vector. A cover starting after\n",
      "u cannot end before this position. On line 4, the algorithm shrinks the interval ending at v,\n",
      "adjusting u so that no smaller interval ending at v contains all the terms. The check at line 5\n",
      "determines whether u and v are contained in the same document. If not, nextCover is called\n",
      "recursively.\n",
      "This last check is required only because the cover will ultimately contribute to a document’s\n",
      "score for ranking. Technically, the interval [1:4, 2:1] is a perfectly acceptable cover for the term\n",
      "vector ⟨“quarrel”,“sir”⟩. However, in a schema-dependent index, a cover that crosses document\n",
      "boundaries is unlikely to be meaningful.\n",
      "Ranking is based on two assumptions: (1) the shorter the cover, the more likely that the\n",
      "text containing the cover is relevant, and (2) the more covers contained in a document, the\n",
      "more likely that the document is relevant. These assumptions are consistent with intuition.\n",
      "The ﬁrst assumption suggests that a score for an individual cover may be based on its length.\n",
      "The second assumption suggests that a document may be assigned a score by summing the\n",
      "individual scores of the covers contained within it. Combining these ideas, we score a document\n",
      "d containing covers [u1,v1], [u2,v2], [u3,v3], ... using the formula\n",
      "score(d) =\n",
      "\u0002 \u0010\n",
      "1\n",
      "vi −ui + 1\n",
      "\u0012\n",
      ".\n",
      "(2.15)\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "62\n",
      "rankProximity (⟨t1, ..., tn⟩, k) ≡\n",
      "1\n",
      "[u, v] ←nextCover(⟨t0, t1, ..., tn⟩, −∞)\n",
      "2\n",
      "d ←docid(u)\n",
      "3\n",
      "score ←0\n",
      "4\n",
      "j ←0\n",
      "5\n",
      "while u < ∞do\n",
      "6\n",
      "if d < docid(u) then\n",
      "7\n",
      "j ←j + 1\n",
      "8\n",
      "Result[j].docid ←d\n",
      "9\n",
      "Result[j].score ←score\n",
      "10\n",
      "d ←docid(u)\n",
      "11\n",
      "score ←0\n",
      "12\n",
      "score ←score + 1/(v −u + 1)\n",
      "13\n",
      "[u, v] ←nextCover(⟨t1, . . . , tn⟩, u)\n",
      "14\n",
      "if d < ∞then\n",
      "15\n",
      "j ←j + 1\n",
      "16\n",
      "Result[j].docid ←d\n",
      "17\n",
      "Result[j].score ←score\n",
      "18\n",
      "sort Result[1..j] by score\n",
      "19\n",
      "return Result[1..k]\n",
      "Figure 2.11\n",
      "Query processing for proximity ranking. The nextCover function from Figure 2.10 is\n",
      "called to generate each cover.\n",
      "Query processing for proximity ranking is presented in Figure 2.11. Covers are generated\n",
      "by calls to the nextCover function and processed one by one in the while loop of lines 5–13.\n",
      "The number of covers κ in the collection is exactly equal to the number of calls to nextCover\n",
      "at line 13. When a document boundary is crossed (line 6), the score and docid are stored in\n",
      "an array of records Result (lines 8–9). After all covers are processed, information on the last\n",
      "document is recorded in the array (lines 14–17), the array is sorted by score (line 18), and the\n",
      "top k documents are returned (line 19).\n",
      "As the rankProximity function makes calls to the nextCover function, the position passed\n",
      "as its second argument strictly increases. In turn, as the nextCover function makes succes-\n",
      "sive calls to the next and prev methods, the values of their second arguments also strictly\n",
      "increase. As we did for the phrase searching algorithm of Section 2.1.1, we may exploit this\n",
      "property by implementing next and prev using galloping search. Following a similar argument,\n",
      "when galloping search is used, the overall time complexity of the rankProximity algorithm is\n",
      "O\n",
      "\u0014\n",
      "n2 l · log (L/l)\n",
      "\u0015\n",
      ".\n",
      "Note that the time complexity is quadratic in n, the size of the term vector, because there\n",
      "may be O(n·l) covers in the worst case. Fortunately, the adaptive nature of the algorithm comes\n",
      "to our assistance again, giving a time complexity of O (n · κ · log (L/κ)).\n",
      "For a document to receive a nonzero score, all terms must be present in it. In this respect,\n",
      "proximity ranking shares the behavior exhibited until recently by many commercial search\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "63\n",
      "engines. When applied to the document collection of Table 2.1 to rank the collection with\n",
      "respect to the query ⟨“you”, “sir”⟩, proximity ranking assigns a score of 0.33 to document 1, a\n",
      "score of 0.53 to document 3, and a score of 0 to the remaining documents.\n",
      "When applied to rank the same collection with respect to the query ⟨“quarrel”,“sir”⟩, the\n",
      "method assigns scores of 0.50 to documents 1 and 2, and a score of 0.00 to documents 3 to 5.\n",
      "Unlike cosine similarity, the second occurrence of “sir” in document 2 does not contribute to\n",
      "the document’s score. The frequency of individual terms is not a factor in proximity ranking;\n",
      "rather, the frequency and proximity of their co-occurrence are factors. It is conceivable that a\n",
      "document could include many matches to all the terms but contain only a single cover, with\n",
      "the query terms clustered into discrete groups.\n",
      "2.2.3\n",
      "Boolean Retrieval\n",
      "Apart from the implicit Boolean ﬁlters applied by Web search engines, explicit support for\n",
      "Boolean queries is important in speciﬁc application areas such as digital libraries and the legal\n",
      "domain. In contrast to ranked retrieval, Boolean retrieval returns sets of documents rather than\n",
      "ranked lists. Under the Boolean retrieval model, a term t is considered to specify the set of\n",
      "documents containing it. The standard Boolean operators (AND, OR, and NOT) are used to\n",
      "construct Boolean queries, which are interpreted as operations over these sets, as follows:\n",
      "A AND B\n",
      "intersection of A and B (A ∩B)\n",
      "A OR B\n",
      "union of A and B (A ∪B)\n",
      "NOT A\n",
      "complement of A with respect to the document collection ( ¯A)\n",
      "where A and B are terms or other Boolean queries. For example, over the collection in Table 2.1,\n",
      "the query\n",
      "(“quarrel” OR “sir”) AND “you”\n",
      "speciﬁes the set {1, 3}, whereas the query\n",
      "(“quarrel” OR “sir”) AND NOT “you”\n",
      "speciﬁes the set {2, 5}.\n",
      "Our algorithm for solving Boolean queries is another variant of the phrase searching algorithm\n",
      "of Figure 2.2 and the cover ﬁnding algorithm of Figure 2.10. The algorithm locates candidate\n",
      "solutions to a Boolean query where each candidate solution represents a range of documents\n",
      "that together satisfy the Boolean query, such that no smaller range of documents contained\n",
      "within it also satisﬁes the query. When the range represented by a candidate solution has a\n",
      "length of 1, this single document satisﬁes the query and should be included in the result set.\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "64\n",
      "The same overall method of operation appears in both of the previous algorithms. In the\n",
      "phrase search algorithm, lines 1–6 identify a range containing all the terms in order, such\n",
      "that no smaller range contained within it also contains all the terms in order. In the cover\n",
      "ﬁnding algorithm, lines 1–4 similarly locate all the terms as close together as possible. In both\n",
      "algorithms an additional constraint is then applied.\n",
      "To simplify our deﬁnition of our Boolean search algorithm, we deﬁne two functions that oper-\n",
      "ate over Boolean queries, extending the nextDoc and prevDoc methods of schema-dependent\n",
      "inverted indices.\n",
      "docRight(Q, u) —\n",
      "end point of the ﬁrst candidate solution to Q starting after\n",
      "document u\n",
      "docLeft(Q, v) —\n",
      "start point of the last candidate solution to Q ending before\n",
      "document v\n",
      "For terms we deﬁne:\n",
      "docRight(t, u)\n",
      "≡\n",
      "nextDoc(t, u)\n",
      "docLeft(t, v)\n",
      "≡\n",
      "prevDoc(t, v)\n",
      "and for the AND and OR operators we deﬁne:\n",
      "docRight(A AND B, u)\n",
      "≡\n",
      "max(docRight(A, u), docRight(B, u))\n",
      "docLeft(A AND B, v)\n",
      "≡\n",
      "min(docLeft(A, v), docLeft(B, v))\n",
      "docRight(A OR B, u)\n",
      "≡\n",
      "min(docRight(A, u), docRight(B, u))\n",
      "docLeft(A OR B, v)\n",
      "≡\n",
      "max(docLeft(A, v), docLeft(B, v))\n",
      "To determine the result for a given query, these deﬁnitions are applied recursively. For example:\n",
      "docRight((“quarrel” OR “sir”) AND “you”, 1)\n",
      "≡max(docRight(“quarrel” OR “sir”, 1), docRight(“you”, 1))\n",
      "≡max(min(docRight(“quarrel”, 1), docRight(“sir”, 1)), nextDoc(“you”, 1))\n",
      "≡max(min(nextDoc(“quarrel”, 1), nextDoc(“sir”, 1)), 3)\n",
      "≡max(min(2, 2), 3)\n",
      "≡3\n",
      "docLeft((“quarrel” OR “sir”) AND “you”, 4)\n",
      "≡min(docLeft(“quarrel” OR “sir”, 4), docLeft(“you”, 4))\n",
      "≡min(max(docLeft(“quarrel”, 4), docLeft(“sir”, 4)), prevDoc(“you”, 4))\n",
      "≡min(max(prevDoc(“quarrel”, 4), prevDoc(“sir”, 4)), 3)\n",
      "≡min(max(2, 3), 3)\n",
      "≡3\n",
      "2.2\n",
      "Retrieval and Ranking\n",
      "65\n",
      "nextSolution (Q, position) ≡\n",
      "1\n",
      "v ←docRight(Q, position)\n",
      "2\n",
      "if v = ∞then\n",
      "3\n",
      "return ∞\n",
      "4\n",
      "u ←docLeft(Q, v + 1)\n",
      "5\n",
      "if u = v then\n",
      "6\n",
      "return u\n",
      "7\n",
      "else\n",
      "8\n",
      "return nextSolution (Q, v)\n",
      "Figure 2.12\n",
      "Function to locate the next solution to the Boolean query Q after a given position. The\n",
      "function nextSolution calls docRight and docLeft to generate a candidate solution. These functions\n",
      "make recursive calls that depend on the structure of the query.\n",
      "Deﬁnitions for the NOT operator are more problematic, and we ignore the operator until after\n",
      "we present the main algorithm.\n",
      "Figure 2.12 presents the nextSolution function, which locates the next solution to a Boolean\n",
      "query after a given position. The function calls docRight and docLeft to generate a candidate\n",
      "solution. Just after line 4, the interval [u,v] contains this candidate solution. If the candidate\n",
      "solution consists of a single document, it is returned. Otherwise, the function makes a recursive\n",
      "call. Given this function, all solutions to Boolean query Q may be generated by the following:\n",
      "u ←−∞\n",
      "while u < ∞do\n",
      "u ←nextSolution(Q, u)\n",
      "if u < ∞then\n",
      "report docid(u)\n",
      "Using a galloping search implementation of nextDoc and prevDoc, the time complexity of this\n",
      "algorithm is O(n·l·log(L/l)), where n is the number of terms in the query. If a docid or frequency\n",
      "index is used, and positional information is not recorded in the index, l and L represent the\n",
      "lengths of the shortest and longest postings lists of the terms in the query as measured by the\n",
      "number of documents. The reasoning required to demonstrate this time complexity is similar to\n",
      "that of our phrase search algorithm and proximity ranking algorithm. When considered in terms\n",
      "of the number of candidate solutions κ, which reﬂects the adaptive nature of the algorithm, the\n",
      "time complexity becomes O(n·κ·log(L/κ)). Note that the call to the docLeft method in line 4\n",
      "of the algorithm can be avoided (see Exercise 2.9), but it helps us to analyze the complexity of\n",
      "the algorithm, by providing a clear deﬁnition of a candidate solution.\n",
      "We ignored the NOT operator in our deﬁnitions of docRight and docLeft. Indeed, it is\n",
      "not necessary to implement general versions of these functions in order to implement the NOT\n",
      "operator. Instead, De Morgan’s laws may be used to transform a query, moving any NOT\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "66\n",
      "operators inward until they are directly associated with query terms:\n",
      "NOT (A AND B)\n",
      "≡\n",
      "NOT A OR NOT B\n",
      "NOT (A OR B)\n",
      "≡\n",
      "NOT A AND NOT B\n",
      "For example, the query\n",
      "“william” AND “shakespeare” AND NOT (“marlowe” OR “bacon”)\n",
      "would be transformed into\n",
      "“william” AND “shakespeare” AND (NOT “marlowe” AND NOT “bacon”) .\n",
      "This transformation does not change the number of AND and OR operators appearing in the\n",
      "query, and hence does not change the number of terms appearing in the query (n). After\n",
      "appropriate application of De Morgan’s laws, we are left with a query containing expressions of\n",
      "the form NOT t, where t is a term. In order to process queries containing expressions of this\n",
      "form, we require corresponding deﬁnitions of docRight and docLeft. It is possible to write\n",
      "these deﬁnitions in terms of nextDoc and prevDoc.\n",
      "docRight(NOT t, u) ≡\n",
      "u′ ←nextDoc(t, u)\n",
      "while u′ = u + 1 do\n",
      "u ←u′\n",
      "u′ ←nextDoc(t, u)\n",
      "return u + 1\n",
      "Unfortunately, this approach introduces potential ineﬃciencies. Although this deﬁnition will\n",
      "exhibit acceptable performance when few documents contain the term t, it may exhibit unac-\n",
      "ceptable performance when most documents contain t, essentially reverting to the linear scan\n",
      "of the postings list that we avoided by introducing galloping search. Moreover, the equiva-\n",
      "lent implementation of docLeft(NOT t, v) requires a scan backward through the postings list,\n",
      "violating the requirement necessary to realize the beneﬁts of galloping search.\n",
      "Instead, we may implement the NOT operator directly over the data structures described in\n",
      "Section 2.1.2, extending the methods supported by our inverted index with explicit methods for\n",
      "nextDoc(NOT t, u) and prevDoc(NOT t, v). We leave the details for Exercise 2.5.\n",
      "2.3\n",
      "Evaluation\n",
      "Our presentation of both cosine similarity and proximity ranking relies heavily on intuition. We\n",
      "appeal to intuition to justify the representation of documents and queries as vectors, to justify\n",
      "the determination of similarity by comparing angles, and to justify the assignment of higher\n",
      "2.3\n",
      "Evaluation\n",
      "67\n",
      "weights when terms appear more frequently or closer together. This reliance on intuition can\n",
      "be accepted only when the methods are eﬀective in practice. Moreover, an implementation of a\n",
      "retrieval method must be eﬃcient enough to compute the results of a typical query in adequate\n",
      "time to satisfy the user, and possible trade-oﬀs between eﬃciency and eﬀectiveness must be\n",
      "considered. A user may not wish to wait for a longer period of time — additional seconds or\n",
      "even minutes — in order to receive a result that is only slightly better than a result she could\n",
      "have received immediately.\n",
      "2.3.1\n",
      "Recall and Precision\n",
      "Measuring the eﬀectiveness of a retrieval method depends on human assessments of relevance.\n",
      "In some cases, it might be possible to infer these assessments implicitly from user behavior. For\n",
      "example, if a user clicks on a result and then quickly backtracks to the result page, we might infer\n",
      "a negative assessment. Nonetheless, most published information retrieval experiments are based\n",
      "on manual assessments created explicitly for experimental purposes, such as the assessments\n",
      "for the TREC experiments described in Chapter 1. These assessments are often binary — an\n",
      "assessor reads the document and judges it relevant or not relevant with respect to a topic. TREC\n",
      "experiments generally use these binary judgments, with a document being judged relevant if\n",
      "any part of it is relevant.\n",
      "For example, given the information need described by TREC topic 426 (Figure 1.8 on page 25),\n",
      "a user might formulate the Boolean query\n",
      "((“law” AND “enforcement”) OR “police”) AND (“dog” OR “dogs”).\n",
      "Running this query over the TREC45 collection produces a set of 881 documents, representing\n",
      "0.17% of the half-million documents in the collection.\n",
      "In order to determine the eﬀectiveness of a Boolean query such as this one, we compare two\n",
      "sets: (1) the set of documents returned by the query, Res, and (2) the set of relevant documents\n",
      "for the topic contained in the collection, Rel. From these two sets we may then compute two\n",
      "standard eﬀectiveness measures: recall and precision.\n",
      "recall\n",
      "=\n",
      "|Rel ∩Res|\n",
      "|Rel|\n",
      "(2.16)\n",
      "precision\n",
      "=\n",
      "|Rel ∩Res|\n",
      "|Res|\n",
      "(2.17)\n",
      "In a nutshell, recall indicates the fraction of relevant documents that appears in the result set,\n",
      "whereas precision indicates the fraction of the result set that is relevant.\n",
      "According to oﬃcial NIST judgments, there are 202 relevant documents in the TREC45 test\n",
      "collection for topic 426. Our query returns 167 of these documents, giving a precision of 0.190\n",
      "and a recall of 0.827. A user may ﬁnd this result acceptable. Just 35 relevant documents are\n",
      "Chapter 2\n",
      "Basic Techniques\n",
      "68\n",
      "outside the result set. However, in order to ﬁnd a relevant document, the user must read an\n",
      "average of 4.28 documents that are not relevant.\n",
      "You will sometimes see recall and precision combined into a single value known as an F-\n",
      "measure. The simplest F-measure, F1, is the harmonic mean of recall and precision:\n",
      "F1 =\n",
      "2\n",
      "1\n",
      "R + 1\n",
      "P\n",
      "= 2 · R · P\n",
      "R + P ,\n",
      "(2.18)\n",
      "where R represents recall and P represents precision. In comparison with the arithmetic mean\n",
      "((R + P)/2), the harmonic mean enforces a balance between recall and precision. For example,\n",
      "if we return the entire collection as the result of a query, recall will be 1 but precision will almost\n",
      "always be close to 0. The arithmetic mean gives a value greater than 0.5 for such a result. In\n",
      "contrast, the harmonic mean gives a value of 2P/(1 + P), which will be close to 0 if P is close\n",
      "to 0.\n",
      "This formula may be generalized through a weighted harmonic mean to allow greater emphasis\n",
      "to be placed on either precision or recall,\n",
      "1\n",
      "α 1\n",
      "R + (1 −α) 1\n",
      "P\n",
      ".\n",
      "(2.19)\n",
      "where 0 ≤α ≤1. For α = 0, the measure is equivalent to precision. For α = 1, it is equivalent to\n",
      "recall. For α = 0.5 it is equivalent to Equation 2.18. Following standard practice (van Rijsbergen,\n",
      "1979, Chapter 7), we set α = 1/(β2 + 1) and deﬁne the F-measure as\n",
      "Fβ = (β2 + 1) · R · P\n",
      "β2 · R + P\n",
      ",\n",
      "(2.20)\n",
      "where β may be any real number. Thus, F0 is recall and F∞is precision. Values of |β| < 1 place\n",
      "emphasis on recall; values of |β| > 1 place emphasis on precision.\n",
      "recall—)precision—)\n",
      "2.3.2\n",
      "Eﬀectiveness Measures for Ranked Retrieval\n",
      "If the user is interested in reading only one or two relevant documents, ranked retrieval may\n",
      "provide a more useful result than Boolean retrieval. To extend our notions of recall and precision\n",
      "to the ordered lists returned by ranked retrieval algorithms, we consider the top k documents\n",
      "returned by a query, Res[1..k], and deﬁne:\n",
      "recall@k\n",
      "=\n",
      "|Rel ∩Res[1..k]|\n",
      "|Rel|\n",
      "(2.21)\n",
      "precision@k\n",
      "=\n",
      "|Rel ∩Res[1..k]|\n",
      "|Res[1..k]|\n",
      ",\n",
      "(2.22)\n",
      "2.3\n",
      "Evaluation\n",
      "69\n",
      "where precision@k is often written as P@k. If we treat the title of topic 426 as a term vector for\n",
      "ranked retrieval, ⟨“law”, “enforcement”, “dogs”⟩, proximity ranking gives P@10 = 0.400 and\n",
      "recall@10 = 0.0198. If the user starts reading from the top of the list, she will ﬁnd four relevant\n",
      "documents in the top ten.\n",
      "By deﬁnition, recall@k increases monotonically with respect to k. Conversely, if a ranked\n",
      "retrieval method adheres to the Probability Ranking Principle deﬁned in Chapter 1 (i.e., ranking\n",
      "documents in order of decreasing probability of relevance), then P@k will tend to decrease as k\n",
      "increases. For topic 426, proximity ranking gives\n",
      "k\n",
      "10\n",
      "20\n",
      "50\n",
      "100\n",
      "200\n",
      "1000\n",
      "P@k\n",
      "0.400\n",
      "0.450\n",
      "0.380\n",
      "0.230\n",
      "0.115\n",
      "0.023\n",
      "recall@k\n",
      "0.020\n",
      "0.045\n",
      "0.094\n",
      "0.114\n",
      "0.114\n",
      "0.114\n",
      "Since only 82 documents contain all of the terms in the query, proximity ranking cannot return\n",
      "200 or 1,000 documents with scores greater than 0. In order to allow comparison with other\n",
      "ranking methods, we compute precision and recall at these values by assuming that the empty\n",
      "lower ranks contain documents that are not relevant. All things considered, a user may be\n",
      "happier with the results of the Boolean query on page 67. But of course the comparison is\n",
      "not\n"
     ]
    }
   ],
   "source": [
    "x = 50000\n",
    "knowledge= text[x:x+131070]\n",
    "print(knowledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.912809Z",
     "iopub.status.busy": "2025-01-24T06:06:47.912481Z",
     "iopub.status.idle": "2025-01-24T06:06:47.925450Z",
     "shell.execute_reply": "2025-01-24T06:06:47.924761Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.912775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_knowledge(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt: str) -> DynamicCache:\n",
    "    \"\"\"\n",
    "    Prepare knowledge kv cache for CAG.\n",
    "    Args:\n",
    "        model: HuggingFace model with automatic device mapping\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        prompt: The knowledge to preprocess, which is basically a prompt\n",
    "\n",
    "    Returns:\n",
    "        DynamicCache: KV Cache\n",
    "    \"\"\"\n",
    "    embed_device = model.model.embed_tokens.weight.device # check which device are used \n",
    "    input_ids    = tokenizer.encode(prompt, return_tensors=\"pt\").to(embed_device)\n",
    "    past_key_values = DynamicCache()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False)\n",
    "    return outputs.past_key_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing Knowledge and Creating Key-Value Cache Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.926486Z",
     "iopub.status.busy": "2025-01-24T06:06:47.926239Z",
     "iopub.status.idle": "2025-01-24T06:06:47.941890Z",
     "shell.execute_reply": "2025-01-24T06:06:47.941078Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.926457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_kvcache(documents, answer_instruction: str = None):\n",
    "    # Prepare the knowledges kvcache\n",
    "\n",
    "    if answer_instruction is None:\n",
    "        answer_instruction = \"Answer the question with a super short answer.\"\n",
    "\n",
    "    knowledges = f\"\"\"\n",
    "    <|begin_of_text|>\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    You are an medical assistant for giving short answers \n",
    "    based on given reports.<|eot_id|>\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    Context information is bellow.\n",
    "    ------------------------------------------------\n",
    "    {documents}\n",
    "    ------------------------------------------------\n",
    "    {answer_instruction}\n",
    "    Question:\n",
    "    \"\"\"\n",
    "    # Get the knowledge cache\n",
    "    kv = preprocess_knowledge(model, tokenizer, knowledges)\n",
    "    kv_len = kv.key_cache[0].shape[-2]\n",
    "    print(\"kvlen: \", kv_len)\n",
    "    return kv, kv_len\n",
    "\n",
    "\n",
    "# kvlen:  610\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 past key value cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.943037Z",
     "iopub.status.busy": "2025-01-24T06:06:47.942749Z",
     "iopub.status.idle": "2025-01-24T06:06:47.959405Z",
     "shell.execute_reply": "2025-01-24T06:06:47.958754Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.943007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_up(kv: DynamicCache, origin_len: int):\n",
    "    \"\"\"\n",
    "    Truncate the KV Cache to the original length.\n",
    "    \"\"\"\n",
    "    for i in range(len(kv.key_cache)):\n",
    "        kv.key_cache[i] = kv.key_cache[i][:, :, :origin_len, :]\n",
    "        kv.value_cache[i] = kv.value_cache[i][:, :, :origin_len, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.961431Z",
     "iopub.status.busy": "2025-01-24T06:06:47.961215Z",
     "iopub.status.idle": "2025-01-24T06:06:47.975240Z",
     "shell.execute_reply": "2025-01-24T06:06:47.974592Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.961413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model,\n",
    "    input_ids: torch.Tensor,\n",
    "    past_key_values,\n",
    "    max_new_tokens: int = 300\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate text with greedy decoding.\n",
    "\n",
    "    Args:\n",
    "        model: HuggingFace model with automatic device mapping\n",
    "        input_ids: Input token ids\n",
    "        past_key_values: KV Cache for knowledge\n",
    "        max_new_tokens: Maximum new tokens to generate\n",
    "    \"\"\"\n",
    "\n",
    "    embed_device = model.model.embed_tokens.weight.device\n",
    "\n",
    "    origin_ids = input_ids # what ?\n",
    "    input_ids = input_ids.to(embed_device)\n",
    "\n",
    "    output_ids = input_ids.clone()\n",
    "    next_token = input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            outputs = model(\n",
    "                input_ids=next_token, \n",
    "                past_key_values=past_key_values,\n",
    "                use_cache=True\n",
    "            )\n",
    "            next_token_logits = outputs.logits[:, -1, :]\n",
    "            next_token = next_token_logits.argmax(dim=-1).unsqueeze(-1)\n",
    "            next_token = next_token.to(embed_device)\n",
    "\n",
    "            past_key_values = outputs.past_key_values\n",
    "\n",
    "            output_ids = torch.cat([output_ids, next_token], dim=1)\n",
    "\n",
    "            \n",
    "            if (next_token.item() in model.config.eos_token_id) and (_ > 0):\n",
    "                break\n",
    "    return output_ids[:, origin_ids.shape[-1]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:06:47.976233Z",
     "iopub.status.busy": "2025-01-24T06:06:47.976045Z",
     "iopub.status.idle": "2025-01-24T06:08:06.752333Z",
     "shell.execute_reply": "2025-01-24T06:08:06.751471Z",
     "shell.execute_reply.started": "2025-01-24T06:06:47.976214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8de1295eb6d407f8efb467d56408251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258d3861e6394791a15b4e080d9d8e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf678737c984b01bce02c1002c89836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aed8b15886d4ab2af670d378d85a189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb666a1438a74cffa5350c7fa24b6210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62346c5a720b498ab013cd69f2254f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,              # Load model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",      # Normalize float 4 quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Compute dtype for 4-bit base matrices\n",
    "    bnb_4bit_use_double_quant=True  # Use nested quantization\n",
    ")\n",
    "\n",
    "\n",
    "def load_quantized_model(model_name, hf_token=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        token=hf_token\n",
    "    )\n",
    "\n",
    "    # Load model with quantization\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",          # Automatically choose best device\n",
    "        trust_remote_code=True,     # Required for some models\n",
    "        token=hf_token\n",
    "    )\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_quantized_model(model_name=MODEL_NAME, hf_token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:12:55.045795Z",
     "iopub.status.busy": "2025-01-24T06:12:55.045403Z",
     "iopub.status.idle": "2025-01-24T06:13:30.367514Z",
     "shell.execute_reply": "2025-01-24T06:13:30.366753Z",
     "shell.execute_reply.started": "2025-01-24T06:12:55.045765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kvlen:  36016\n",
      "Response of the model:\n",
      " assistant\n",
      "\n",
      "This is about the cosine similarity and proximity ranking methods used in information retrieval.\n",
      "Elapsed time: 35.316410303115845 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "knowledge_cache, kv_len  = prepare_kvcache(documents =knowledge)\n",
    "# query = 'which Patient experienced issues with blood glucose meter, what was the problem ?'\n",
    "query = 'What is this about?.'\n",
    "clean_up(knowledge_cache, kv_len)\n",
    "input_ids = tokenizer.encode(query, return_tensors=\"pt\").to(model.device)\n",
    "output = generate(model, input_ids, knowledge_cache)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True, temperature=None)\n",
    "print(f\"Response of the model:\\n {generated_text}\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T06:08:42.892726Z",
     "iopub.status.busy": "2025-01-24T06:08:42.892369Z",
     "iopub.status.idle": "2025-01-24T06:08:42.897336Z",
     "shell.execute_reply": "2025-01-24T06:08:42.896500Z",
     "shell.execute_reply.started": "2025-01-24T06:08:42.892693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def write_kv_cache(kv: DynamicCache, path: str):\n",
    "    \"\"\"\n",
    "    Write the KV Cache to a file.\n",
    "    \"\"\"\n",
    "    torch.save(kv, path)\n",
    "\n",
    "def read_kv_cache(path: str) -> DynamicCache:\n",
    "    \"\"\"\n",
    "    Read the KV Cache from a file.\n",
    "    \"\"\"\n",
    "    kv = torch.load(path, weights_only=True)\n",
    "    return kv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6538049,
     "sourceId": 10565763,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
